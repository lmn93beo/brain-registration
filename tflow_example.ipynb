{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load processed images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_matching_ylabel(filename, ytable):\n",
    "    '''\n",
    "    Returns the corresponding AP coordinate\n",
    "    \n",
    "    Inputs:\n",
    "    - filename: the name of the image file *.tif\n",
    "    - ytable: the AP coords in the form of a pd table\n",
    "    \n",
    "    Returns: the AP coordinate, None if no match\n",
    "    '''\n",
    "    for id, label_name in enumerate(ytable.Image):\n",
    "        #print(id, label_name)\n",
    "        if filename.startswith(label_name + '_'):\n",
    "            return ytable.AP[id]\n",
    "    \n",
    "    print('Warning: no match')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_datasets(X, y):\n",
    "    '''Shuffle the datasets'''\n",
    "    order = np.random.permutation(len(y))\n",
    "    return X[order], y[order]\n",
    "    \n",
    "def load_dataset(folder, ylabel_file, num_training, num_validation, num_test):\n",
    "    '''\n",
    "    Loads a dataset\n",
    "    \n",
    "    Inputs:\n",
    "    - filename: name of the file\n",
    "    - ylabel_file: name of the ground truth label file\n",
    "    \n",
    "    Outputs:\n",
    "    Xtrain, ytrain, Xval, yval, Xtest, ytest\n",
    "    '''\n",
    "    # Now load the labels\n",
    "    y_table = pd.read_csv(ylabel_file)\n",
    "    \n",
    "    # Load the images in the folder\n",
    "    files = glob.glob(folder)\n",
    "    imlst = []\n",
    "    y_train = []\n",
    "    \n",
    "    for file in files:\n",
    "        filename = file.split('\\\\')[-1]\n",
    "        im = Image.open(file)\n",
    "                \n",
    "        # Find the corresponding AP\n",
    "        APval = find_matching_ylabel(filename, y_table)\n",
    "        \n",
    "        imlst.append(np.array(im))\n",
    "        y_train.append(APval)\n",
    "        #print(filename, APval)\n",
    "        \n",
    "    y_train = np.array(y_train)\n",
    "    print(np.array(imlst).shape)\n",
    "    X_train = np.array(imlst)[:,:,:,np.newaxis] # Dimension N x W x H x 1 (1 channel)\n",
    "    assert len(y_train) == X_train.shape[0], \"Training and labels mismatch in length\"\n",
    "    \n",
    "    # Shuffle!\n",
    "    X_train, y_train = shuffle_datasets(X_train, y_train)\n",
    "\n",
    "    # Training and validation set\n",
    "    # Subsample the data\n",
    "    mask = range(num_training, num_training + num_validation)\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    \n",
    "    mask = range(num_training + num_validation, num_training + num_validation + num_test)\n",
    "    X_test = X_train[mask]\n",
    "    y_test = y_train[mask]\n",
    "    \n",
    "    mask = range(num_training)\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    \n",
    "\n",
    "    # Normalize the data: subtract the mean pixel and divide by std\n",
    "    #mean_pixel = X_train.mean(axis=(0, 1, 2), keepdims=True)\n",
    "    #std_pixel = X_train.std(axis=(0, 1, 2), keepdims=True)\n",
    "    #X_train = (X_train - mean_pixel) / std_pixel\n",
    "    #X_val = (X_val - mean_pixel) / std_pixel\n",
    "    #X_test = (X_test - mean_pixel) / std_pixel\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_multiple(folder_lst, ylabel_lst, num_training, num_validation, num_test):\n",
    "    '''\n",
    "    Load from multiple folders\n",
    "    \n",
    "    Inputs:\n",
    "    - folder_lst: list of folders\n",
    "    - ylabel_lst: list of ylabel files\n",
    "    - num_training: list or array of number of training in each file\n",
    "    - num_validation: list of number of validation examples in each file\n",
    "    - num_test: list of number of test examples in each file\n",
    "    \n",
    "    Returns: \n",
    "    Xtrain, ytrain, Xval, yval, Xtest, ytest\n",
    "    '''\n",
    "    X_train_all, y_train_all, X_val_all, y_val_all, X_test_all, y_test_all = [], [], [], [], [], []\n",
    "    for folder, ylabel_file, ntrain, nval, ntest in zip(folder_lst, \\\n",
    "                                    ylabel_lst, num_training, num_validation, num_test):\n",
    "        X_train, y_train, X_val, y_val, X_test, y_test = load_dataset(folder, \\\n",
    "                                            ylabel_file, ntrain, nval, ntest)\n",
    "        print(y_train)\n",
    "        X_train_all.append(X_train)\n",
    "        y_train_all.append(y_train)\n",
    "        X_val_all.append(X_val)\n",
    "        y_val_all.append(y_val)\n",
    "        X_test_all.append(X_test)\n",
    "        y_test_all.append(y_test)\n",
    "        \n",
    "    # Concatenate and shuffle again\n",
    "    X_train_all = np.concatenate(X_train_all)\n",
    "    y_train_all = np.concatenate(y_train_all)\n",
    "    X_val_all = np.concatenate(X_val_all)\n",
    "    y_val_all = np.concatenate(y_val_all)\n",
    "    X_test_all = np.concatenate(X_test_all)\n",
    "    y_test_all = np.concatenate(y_test_all)\n",
    "    \n",
    "    X_train_all, y_train_all = shuffle_datasets(X_train_all, y_train_all)\n",
    "    X_val_all, y_val_all = shuffle_datasets(X_val_all, y_val_all)\n",
    "    X_test_all, y_test_all = shuffle_datasets(X_test_all, y_test_all)\n",
    "    \n",
    "    return X_train_all, y_train_all, X_val_all, y_val_all, \\\n",
    "            X_test_all, y_test_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51, 80, 100)\n",
      "[ 0.05  0.15 -2.8   2.1   0.6  -2.8  -3.    1.   -0.4  -2.6   1.2   1.8\n",
      " -2.9  -0.7   2.2  -2.4  -2.7   0.2  -2.5   2.    0.3   0.1  -2.5  -2.6\n",
      " -0.2  -2.3   0.25  1.1  -0.6  -2.9   1.7  -0.9   1.9  -0.3  -3.1   1.5\n",
      " -2.1  -2.7   2.4  -0.5 ]\n",
      "(38, 80, 100)\n",
      "[ 0.4  2.3 -3.4 -3.7 -3.9  0.1 -1.  -1.3  0.6 -2.1 -0.5  1.7 -1.9 -3.5\n",
      " -0.3  1.2 -2.7 -1.6 -2.4 -0.8 -3.1 -2.9 -0.6  1.1 -2.5 -4.1 -0.2  1.9]\n"
     ]
    }
   ],
   "source": [
    "folder_lst = ['C:\\\\Users\\\\Sur lab\\\\Documents\\\\allenCCF\\\\C07_small\\\\*.png', \\\n",
    "             'C:\\\\Users\\\\Sur lab\\\\Documents\\\\allenCCF\\\\C20_small\\\\*.tif']\n",
    "ylabel_lst = ['human_label_APcoords.csv', 'human_label_APcoords_C20.csv']\n",
    "num_training = [40, 28]\n",
    "num_validation = [6, 6]\n",
    "num_test = [5, 4]\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_dataset_multiple(folder_lst, \\\n",
    "                                    ylabel_lst, num_training, num_validation, num_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_Xy(X_train, y_train, naugment=50, crop_extent=10):\n",
    "    '''Augment the data and shuffle\n",
    "    Inputs:\n",
    "    -X_train, y_train, the training data\n",
    "    - naugment: how many times to augment (x2 for flipping)\n",
    "    - crop_extent: how far a crop can go\n",
    "    \n",
    "    Outputs: X_aug, y_aug: the augmented data'''\n",
    "    imlst = []\n",
    "\n",
    "    # Applying only to training set?\n",
    "    for i in range(X_train.shape[0]):\n",
    "        image = X_train[i,:,:,0]\n",
    "        image = Image.fromarray(image)\n",
    "\n",
    "        for j in range(naugment):\n",
    "            # Pick a random angle\n",
    "            angle = np.random.rand() * crop_extent * 2 - crop_extent\n",
    "            ver_crop = np.random.rand() * crop_extent * 2 - crop_extent\n",
    "            hor_crop = np.random.rand() * crop_extent * 2 - crop_extent\n",
    "\n",
    "            modified1 = image.rotate(angle).crop((ver_crop, hor_crop, ver_crop+X_train.shape[2], hor_crop+X_train.shape[1]))\n",
    "            modified2 = modified1.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "\n",
    "            modified1 = np.array(modified1)[:,:,np.newaxis] / 256\n",
    "            modified2 = np.array(modified2)[:,:,np.newaxis] / 256\n",
    "\n",
    "            imlst += [modified1, modified2]\n",
    "\n",
    "    X_train_aug = np.array(imlst)\n",
    "    y_train_aug = y_train.repeat(naugment * 2)\n",
    "    return shuffle_datasets(X_train_aug, y_train_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_aug, y_train_aug = augment_Xy(X_train, y_train, 50, 10)\n",
    "X_val_aug, y_val_aug = augment_Xy(X_val, y_val, 50, 10)\n",
    "X_test_aug, y_test_aug = augment_Xy(X_test, y_test, 50, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "id = 5\n",
    "plt.imshow(X_val_aug[id,:,:,0])\n",
    "print(y_val_aug[id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run NN model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    def __init__(self, X, y, batch_size, shuffle=False):\n",
    "        \"\"\"\n",
    "        Construct a Dataset object to iterate over data X and labels y\n",
    "        \n",
    "        Inputs:\n",
    "        - X: Numpy array of data, of any shape\n",
    "        - y: Numpy array of labels, of any shape but with y.shape[0] == X.shape[0]\n",
    "        - batch_size: Integer giving number of elements per minibatch\n",
    "        - shuffle: (optional) Boolean, whether to shuffle the data on each epoch\n",
    "        \"\"\"\n",
    "        assert X.shape[0] == y.shape[0], 'Got different numbers of data and labels'\n",
    "        self.X, self.y = X, y\n",
    "        self.batch_size, self.shuffle = batch_size, shuffle\n",
    "\n",
    "    def __iter__(self):\n",
    "        N, B = self.X.shape[0], self.batch_size\n",
    "        idxs = np.arange(N)\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(idxs)\n",
    "        return iter((self.X[i:i+B], self.y[i:i+B]) for i in range(0, N, B))\n",
    "\n",
    "\n",
    "train_dset = Dataset(X_train_aug, y_train_aug, batch_size=100, shuffle=True)\n",
    "val_dset = Dataset(X_val, y_val, batch_size=5, shuffle=False)\n",
    "test_dset = Dataset(X_test, y_test, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (100, 80, 100, 1) (100,)\n",
      "1 (100, 80, 100, 1) (100,)\n",
      "2 (100, 80, 100, 1) (100,)\n",
      "3 (100, 80, 100, 1) (100,)\n",
      "4 (100, 80, 100, 1) (100,)\n",
      "5 (100, 80, 100, 1) (100,)\n",
      "6 (100, 80, 100, 1) (100,)\n"
     ]
    }
   ],
   "source": [
    "# We can iterate through a dataset like this:\n",
    "for t, (x, y) in enumerate(train_dset):\n",
    "    print(t, x.shape, y.shape)\n",
    "    if t > 5: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:  /cpu:0\n"
     ]
    }
   ],
   "source": [
    "# Set up some global variables\n",
    "USE_GPU = False\n",
    "\n",
    "if USE_GPU:\n",
    "    device = '/device:GPU:0'\n",
    "else:\n",
    "    device = '/cpu:0'\n",
    "\n",
    "# Constant to control how often we print when training models\n",
    "print_every = 100\n",
    "\n",
    "print('Using device: ', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_part34(model_init_fn, optimizer_init_fn, num_epochs=1):\n",
    "    \"\"\"\n",
    "    Simple training loop for use with models defined using tf.keras. It trains\n",
    "    a model for one epoch on the CIFAR-10 training set and periodically checks\n",
    "    accuracy on the CIFAR-10 validation set.\n",
    "    \n",
    "    Inputs:\n",
    "    - model_init_fn: A function that takes no parameters; when called it\n",
    "      constructs the model we want to train: model = model_init_fn()\n",
    "    - optimizer_init_fn: A function which takes no parameters; when called it\n",
    "      constructs the Optimizer object we will use to optimize the model:\n",
    "      optimizer = optimizer_init_fn()\n",
    "    - num_epochs: The number of epochs to train for\n",
    "    \n",
    "    Returns: Nothing, but prints progress during trainingn\n",
    "    \"\"\"\n",
    "    tf.reset_default_graph()    \n",
    "    with tf.device(device):\n",
    "        # Construct the computational graph we will use to train the model. We\n",
    "        # use the model_init_fn to construct the model, declare placeholders for\n",
    "        # the data and labels\n",
    "        x = tf.placeholder(tf.float32, [None, 80, 100, 1])\n",
    "        y = tf.placeholder(tf.int32, [None])\n",
    "        \n",
    "        # We need a place holder to explicitly specify if the model is in the training\n",
    "        # phase or not. This is because a number of layers behaves differently in\n",
    "        # training and in testing, e.g., dropout and batch normalization.\n",
    "        # We pass this variable to the computation graph through feed_dict as shown below.\n",
    "        is_training = tf.placeholder(tf.bool, name='is_training')\n",
    "        \n",
    "        # Use the model function to build the forward pass.\n",
    "        scores = model_init_fn(x, is_training)\n",
    "\n",
    "        # Compute the loss like we did in Part II\n",
    "        loss = tf.losses.mean_squared_error(labels=y, predictions=tf.reshape(scores, [-1]))\n",
    "        #loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=scores)\n",
    "        loss = tf.reduce_mean(loss)\n",
    "\n",
    "        # Use the optimizer_fn to construct an Optimizer, then use the optimizer\n",
    "        # to set up the training step. Asking TensorFlow to evaluate the\n",
    "        # train_op returned by optimizer.minimize(loss) will cause us to make a\n",
    "        # single update step using the current minibatch of data.\n",
    "        \n",
    "        # Note that we use tf.control_dependencies to force the model to run\n",
    "        # the tf.GraphKeys.UPDATE_OPS at each training step. tf.GraphKeys.UPDATE_OPS\n",
    "        # holds the operators that update the states of the network.\n",
    "        # For example, the tf.layers.batch_normalization function adds the running mean\n",
    "        # and variance update operators to tf.GraphKeys.UPDATE_OPS.\n",
    "        optimizer = optimizer_init_fn()\n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(update_ops):\n",
    "            train_op = optimizer.minimize(loss)\n",
    "\n",
    "    # Now we can run the computational graph many times to train the model.\n",
    "    # When we call sess.run we ask it to evaluate train_op, which causes the\n",
    "    # model to update.\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        t = 0\n",
    "        for epoch in range(num_epochs):\n",
    "            print('Starting epoch %d' % epoch)\n",
    "            for x_np, y_np in train_dset:\n",
    "                feed_dict = {x: x_np, y: y_np, is_training:1}\n",
    "                loss_np, _ = sess.run([loss, train_op], feed_dict=feed_dict)\n",
    "                if t % print_every == 0:\n",
    "                    print('Iteration %d, loss = %.4f' % (t, loss_np))\n",
    "                    check_accuracy(sess, val_dset, x, scores, is_training=is_training)\n",
    "                    #print()\n",
    "                t += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerFC(tf.keras.Model):\n",
    "    def __init__(self, hidden_size, num_classes):\n",
    "        super().__init__()        \n",
    "        initializer = tf.variance_scaling_initializer(scale=2.0)\n",
    "        self.fc1 = tf.layers.Dense(hidden_size, activation=tf.nn.relu,\n",
    "                                   kernel_initializer=initializer)\n",
    "        self.fc2 = tf.layers.Dense(num_classes,\n",
    "                                   kernel_initializer=initializer)\n",
    "    def call(self, x, training=None):\n",
    "        x = tf.layers.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(sess, dset, x, scores, is_training=None):\n",
    "    \"\"\"\n",
    "    Check accuracy on a classification model.\n",
    "    \n",
    "    Inputs:\n",
    "    - sess: A TensorFlow Session that will be used to run the graph\n",
    "    - dset: A Dataset object on which to check accuracy\n",
    "    - x: A TensorFlow placeholder Tensor where input images should be fed\n",
    "    - scores: A TensorFlow Tensor representing the scores output from the\n",
    "      model; this is the Tensor we will ask TensorFlow to evaluate.\n",
    "      \n",
    "    Returns: Nothing, but prints the accuracy of the model\n",
    "    \"\"\"\n",
    "    num_correct, num_samples = 0, 0\n",
    "    loss_total = 0\n",
    "    ntotal = 0\n",
    "    for x_batch, y_batch in dset:\n",
    "        feed_dict = {x: x_batch, is_training: 0}\n",
    "        scores_np = sess.run(scores, feed_dict=feed_dict)\n",
    "        loss_total += np.sum((scores_np.flatten() - y_batch.flatten()) ** 2)\n",
    "        ntotal += len(y_batch)\n",
    "        #print(ntotal)\n",
    "        \n",
    "    print('Validation loss = %.2f' % np.sqrt(loss_total / ntotal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 0\n",
      "Iteration 0, loss = 3.3121\n",
      "Validation loss = 1588.24\n",
      "Starting epoch 1\n",
      "Iteration 100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 2\n",
      "Iteration 200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Iteration 300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 5\n",
      "Iteration 400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 6\n",
      "Starting epoch 7\n",
      "Iteration 500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 8\n",
      "Iteration 600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 9\n",
      "Starting epoch 10\n",
      "Iteration 700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 11\n",
      "Iteration 800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 12\n",
      "Starting epoch 13\n",
      "Iteration 900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 14\n",
      "Iteration 1000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 15\n",
      "Starting epoch 16\n",
      "Iteration 1100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 17\n",
      "Iteration 1200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 18\n",
      "Starting epoch 19\n",
      "Iteration 1300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 20\n",
      "Iteration 1400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 21\n",
      "Starting epoch 22\n",
      "Iteration 1500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 23\n",
      "Iteration 1600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 24\n",
      "Starting epoch 25\n",
      "Iteration 1700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 26\n",
      "Iteration 1800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 27\n",
      "Iteration 1900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 28\n",
      "Starting epoch 29\n",
      "Iteration 2000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 30\n",
      "Iteration 2100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 31\n",
      "Starting epoch 32\n",
      "Iteration 2200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 33\n",
      "Iteration 2300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 34\n",
      "Starting epoch 35\n",
      "Iteration 2400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 36\n",
      "Iteration 2500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 37\n",
      "Starting epoch 38\n",
      "Iteration 2600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 39\n",
      "Iteration 2700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 40\n",
      "Starting epoch 41\n",
      "Iteration 2800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 42\n",
      "Iteration 2900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 43\n",
      "Starting epoch 44\n",
      "Iteration 3000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 45\n",
      "Iteration 3100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 46\n",
      "Starting epoch 47\n",
      "Iteration 3200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 48\n",
      "Iteration 3300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 49\n",
      "Starting epoch 50\n",
      "Iteration 3400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 51\n",
      "Iteration 3500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 52\n",
      "Iteration 3600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 53\n",
      "Starting epoch 54\n",
      "Iteration 3700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 55\n",
      "Iteration 3800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 56\n",
      "Starting epoch 57\n",
      "Iteration 3900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 58\n",
      "Iteration 4000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 59\n",
      "Starting epoch 60\n",
      "Iteration 4100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 61\n",
      "Iteration 4200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 62\n",
      "Starting epoch 63\n",
      "Iteration 4300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 64\n",
      "Iteration 4400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 65\n",
      "Starting epoch 66\n",
      "Iteration 4500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 67\n",
      "Iteration 4600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 68\n",
      "Starting epoch 69\n",
      "Iteration 4700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 70\n",
      "Iteration 4800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 71\n",
      "Starting epoch 72\n",
      "Iteration 4900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 73\n",
      "Iteration 5000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 74\n",
      "Starting epoch 75\n",
      "Iteration 5100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 76\n",
      "Iteration 5200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 77\n",
      "Iteration 5300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 78\n",
      "Starting epoch 79\n",
      "Iteration 5400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 80\n",
      "Iteration 5500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 81\n",
      "Starting epoch 82\n",
      "Iteration 5600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 83\n",
      "Iteration 5700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 84\n",
      "Starting epoch 85\n",
      "Iteration 5800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 86\n",
      "Iteration 5900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 87\n",
      "Starting epoch 88\n",
      "Iteration 6000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 89\n",
      "Iteration 6100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 90\n",
      "Starting epoch 91\n",
      "Iteration 6200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 92\n",
      "Iteration 6300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 93\n",
      "Starting epoch 94\n",
      "Iteration 6400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 95\n",
      "Iteration 6500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 96\n",
      "Starting epoch 97\n",
      "Iteration 6600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 98\n",
      "Iteration 6700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 99\n",
      "Starting epoch 100\n",
      "Iteration 6800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 101\n",
      "Iteration 6900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 102\n",
      "Iteration 7000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 103\n",
      "Starting epoch 104\n",
      "Iteration 7100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 105\n",
      "Iteration 7200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 106\n",
      "Starting epoch 107\n",
      "Iteration 7300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 108\n",
      "Iteration 7400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 109\n",
      "Starting epoch 110\n",
      "Iteration 7500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 111\n",
      "Iteration 7600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 112\n",
      "Starting epoch 113\n",
      "Iteration 7700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 114\n",
      "Iteration 7800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 115\n",
      "Starting epoch 116\n",
      "Iteration 7900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 117\n",
      "Iteration 8000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 118\n",
      "Starting epoch 119\n",
      "Iteration 8100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 120\n",
      "Iteration 8200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 121\n",
      "Starting epoch 122\n",
      "Iteration 8300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 123\n",
      "Iteration 8400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 124\n",
      "Starting epoch 125\n",
      "Iteration 8500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 126\n",
      "Iteration 8600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 127\n",
      "Iteration 8700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 128\n",
      "Starting epoch 129\n",
      "Iteration 8800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 130\n",
      "Iteration 8900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 131\n",
      "Starting epoch 132\n",
      "Iteration 9000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 133\n",
      "Iteration 9100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 134\n",
      "Starting epoch 135\n",
      "Iteration 9200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 136\n",
      "Iteration 9300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 137\n",
      "Starting epoch 138\n",
      "Iteration 9400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 139\n",
      "Iteration 9500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 140\n",
      "Starting epoch 141\n",
      "Iteration 9600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 142\n",
      "Iteration 9700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 143\n",
      "Starting epoch 144\n",
      "Iteration 9800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 145\n",
      "Iteration 9900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 146\n",
      "Starting epoch 147\n",
      "Iteration 10000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 148\n",
      "Iteration 10100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 149\n",
      "Starting epoch 150\n",
      "Iteration 10200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 151\n",
      "Iteration 10300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 152\n",
      "Iteration 10400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 153\n",
      "Starting epoch 154\n",
      "Iteration 10500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 155\n",
      "Iteration 10600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 156\n",
      "Starting epoch 157\n",
      "Iteration 10700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 159\n",
      "Starting epoch 160\n",
      "Iteration 10900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 161\n",
      "Iteration 11000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 162\n",
      "Starting epoch 163\n",
      "Iteration 11100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 164\n",
      "Iteration 11200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 165\n",
      "Starting epoch 166\n",
      "Iteration 11300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 167\n",
      "Iteration 11400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 168\n",
      "Starting epoch 169\n",
      "Iteration 11500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 170\n",
      "Iteration 11600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 171\n",
      "Starting epoch 172\n",
      "Iteration 11700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 173\n",
      "Iteration 11800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 174\n",
      "Starting epoch 175\n",
      "Iteration 11900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 176\n",
      "Iteration 12000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 177\n",
      "Iteration 12100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 178\n",
      "Starting epoch 179\n",
      "Iteration 12200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 180\n",
      "Iteration 12300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 181\n",
      "Starting epoch 182\n",
      "Iteration 12400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 183\n",
      "Iteration 12500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 184\n",
      "Starting epoch 185\n",
      "Iteration 12600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 186\n",
      "Iteration 12700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 187\n",
      "Starting epoch 188\n",
      "Iteration 12800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 189\n",
      "Iteration 12900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 190\n",
      "Starting epoch 191\n",
      "Iteration 13000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 192\n",
      "Iteration 13100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 193\n",
      "Starting epoch 194\n",
      "Iteration 13200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 195\n",
      "Iteration 13300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 196\n",
      "Starting epoch 197\n",
      "Iteration 13400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 198\n",
      "Iteration 13500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 199\n",
      "Starting epoch 200\n",
      "Iteration 13600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 201\n",
      "Iteration 13700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 202\n",
      "Iteration 13800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 203\n",
      "Starting epoch 204\n",
      "Iteration 13900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 205\n",
      "Iteration 14000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 206\n",
      "Starting epoch 207\n",
      "Iteration 14100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 208\n",
      "Iteration 14200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 209\n",
      "Starting epoch 210\n",
      "Iteration 14300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 211\n",
      "Iteration 14400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 212\n",
      "Starting epoch 213\n",
      "Iteration 14500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 214\n",
      "Iteration 14600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 215\n",
      "Starting epoch 216\n",
      "Iteration 14700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 217\n",
      "Iteration 14800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 218\n",
      "Starting epoch 219\n",
      "Iteration 14900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 220\n",
      "Iteration 15000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 221\n",
      "Starting epoch 222\n",
      "Iteration 15100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 223\n",
      "Iteration 15200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 224\n",
      "Starting epoch 225\n",
      "Iteration 15300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 226\n",
      "Iteration 15400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 227\n",
      "Iteration 15500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 228\n",
      "Starting epoch 229\n",
      "Iteration 15600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 230\n",
      "Iteration 15700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 231\n",
      "Starting epoch 232\n",
      "Iteration 15800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 233\n",
      "Iteration 15900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 234\n",
      "Starting epoch 235\n",
      "Iteration 16000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 236\n",
      "Iteration 16100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 237\n",
      "Starting epoch 238\n",
      "Iteration 16200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 239\n",
      "Iteration 16300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 240\n",
      "Starting epoch 241\n",
      "Iteration 16400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 242\n",
      "Iteration 16500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 243\n",
      "Starting epoch 244\n",
      "Iteration 16600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 245\n",
      "Iteration 16700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 246\n",
      "Starting epoch 247\n",
      "Iteration 16800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 248\n",
      "Iteration 16900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 249\n",
      "Starting epoch 250\n",
      "Iteration 17000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 251\n",
      "Iteration 17100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 252\n",
      "Iteration 17200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 253\n",
      "Starting epoch 254\n",
      "Iteration 17300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 255\n",
      "Iteration 17400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 256\n",
      "Starting epoch 257\n",
      "Iteration 17500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 258\n",
      "Iteration 17600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 259\n",
      "Starting epoch 260\n",
      "Iteration 17700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 261\n",
      "Iteration 17800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 262\n",
      "Starting epoch 263\n",
      "Iteration 17900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 264\n",
      "Iteration 18000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 265\n",
      "Starting epoch 266\n",
      "Iteration 18100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 267\n",
      "Iteration 18200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 268\n",
      "Starting epoch 269\n",
      "Iteration 18300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 270\n",
      "Iteration 18400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 271\n",
      "Starting epoch 272\n",
      "Iteration 18500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 273\n",
      "Iteration 18600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 274\n",
      "Starting epoch 275\n",
      "Iteration 18700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 276\n",
      "Iteration 18800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 277\n",
      "Iteration 18900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 278\n",
      "Starting epoch 279\n",
      "Iteration 19000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 280\n",
      "Iteration 19100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 281\n",
      "Starting epoch 282\n",
      "Iteration 19200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 283\n",
      "Iteration 19300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 284\n",
      "Starting epoch 285\n",
      "Iteration 19400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 286\n",
      "Iteration 19500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 287\n",
      "Starting epoch 288\n",
      "Iteration 19600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 289\n",
      "Iteration 19700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 290\n",
      "Starting epoch 291\n",
      "Iteration 19800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 292\n",
      "Iteration 19900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 293\n",
      "Starting epoch 294\n",
      "Iteration 20000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 295\n",
      "Iteration 20100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 296\n",
      "Starting epoch 297\n",
      "Iteration 20200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 298\n",
      "Iteration 20300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 299\n",
      "Starting epoch 300\n",
      "Iteration 20400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 301\n",
      "Iteration 20500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 302\n",
      "Iteration 20600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 303\n",
      "Starting epoch 304\n",
      "Iteration 20700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 305\n",
      "Iteration 20800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 306\n",
      "Starting epoch 307\n",
      "Iteration 20900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 308\n",
      "Iteration 21000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 309\n",
      "Starting epoch 310\n",
      "Iteration 21100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 311\n",
      "Iteration 21200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 312\n",
      "Starting epoch 313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 21300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 314\n",
      "Iteration 21400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 315\n",
      "Starting epoch 316\n",
      "Iteration 21500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 317\n",
      "Iteration 21600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 318\n",
      "Starting epoch 319\n",
      "Iteration 21700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 320\n",
      "Iteration 21800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 321\n",
      "Starting epoch 322\n",
      "Iteration 21900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 323\n",
      "Iteration 22000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 324\n",
      "Starting epoch 325\n",
      "Iteration 22100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 326\n",
      "Iteration 22200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 327\n",
      "Iteration 22300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 328\n",
      "Starting epoch 329\n",
      "Iteration 22400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 330\n",
      "Iteration 22500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 331\n",
      "Starting epoch 332\n",
      "Iteration 22600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 333\n",
      "Iteration 22700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 334\n",
      "Starting epoch 335\n",
      "Iteration 22800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 336\n",
      "Iteration 22900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 337\n",
      "Starting epoch 338\n",
      "Iteration 23000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 339\n",
      "Iteration 23100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 340\n",
      "Starting epoch 341\n",
      "Iteration 23200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 342\n",
      "Iteration 23300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 343\n",
      "Starting epoch 344\n",
      "Iteration 23400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 345\n",
      "Iteration 23500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 346\n",
      "Starting epoch 347\n",
      "Iteration 23600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 348\n",
      "Iteration 23700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 349\n",
      "Starting epoch 350\n",
      "Iteration 23800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 351\n",
      "Iteration 23900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 352\n",
      "Iteration 24000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 353\n",
      "Starting epoch 354\n",
      "Iteration 24100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 355\n",
      "Iteration 24200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 356\n",
      "Starting epoch 357\n",
      "Iteration 24300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 358\n",
      "Iteration 24400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 359\n",
      "Starting epoch 360\n",
      "Iteration 24500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 361\n",
      "Iteration 24600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 362\n",
      "Starting epoch 363\n",
      "Iteration 24700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 364\n",
      "Iteration 24800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 365\n",
      "Starting epoch 366\n",
      "Iteration 24900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 367\n",
      "Iteration 25000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 368\n",
      "Starting epoch 369\n",
      "Iteration 25100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 370\n",
      "Iteration 25200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 371\n",
      "Starting epoch 372\n",
      "Iteration 25300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 373\n",
      "Iteration 25400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 374\n",
      "Starting epoch 375\n",
      "Iteration 25500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 376\n",
      "Iteration 25600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 377\n",
      "Iteration 25700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 378\n",
      "Starting epoch 379\n",
      "Iteration 25800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 380\n",
      "Iteration 25900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 381\n",
      "Starting epoch 382\n",
      "Iteration 26000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 383\n",
      "Iteration 26100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 384\n",
      "Starting epoch 385\n",
      "Iteration 26200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 386\n",
      "Iteration 26300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 387\n",
      "Starting epoch 388\n",
      "Iteration 26400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 389\n",
      "Iteration 26500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 390\n",
      "Starting epoch 391\n",
      "Iteration 26600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 392\n",
      "Iteration 26700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 393\n",
      "Starting epoch 394\n",
      "Iteration 26800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 395\n",
      "Iteration 26900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 396\n",
      "Starting epoch 397\n",
      "Iteration 27000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 398\n",
      "Iteration 27100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 399\n",
      "Starting epoch 400\n",
      "Iteration 27200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 401\n",
      "Iteration 27300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 402\n",
      "Iteration 27400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 403\n",
      "Starting epoch 404\n",
      "Iteration 27500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 405\n",
      "Iteration 27600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 406\n",
      "Starting epoch 407\n",
      "Iteration 27700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 408\n",
      "Iteration 27800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 409\n",
      "Starting epoch 410\n",
      "Iteration 27900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 411\n",
      "Iteration 28000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 412\n",
      "Starting epoch 413\n",
      "Iteration 28100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 414\n",
      "Iteration 28200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 415\n",
      "Starting epoch 416\n",
      "Iteration 28300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 417\n",
      "Iteration 28400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 418\n",
      "Starting epoch 419\n",
      "Iteration 28500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 420\n",
      "Iteration 28600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 421\n",
      "Starting epoch 422\n",
      "Iteration 28700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 423\n",
      "Iteration 28800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 424\n",
      "Starting epoch 425\n",
      "Iteration 28900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 426\n",
      "Iteration 29000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 427\n",
      "Iteration 29100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 428\n",
      "Starting epoch 429\n",
      "Iteration 29200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 430\n",
      "Iteration 29300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 431\n",
      "Starting epoch 432\n",
      "Iteration 29400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 433\n",
      "Iteration 29500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 434\n",
      "Starting epoch 435\n",
      "Iteration 29600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 436\n",
      "Iteration 29700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 437\n",
      "Starting epoch 438\n",
      "Iteration 29800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 439\n",
      "Iteration 29900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 440\n",
      "Starting epoch 441\n",
      "Iteration 30000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 442\n",
      "Iteration 30100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 443\n",
      "Starting epoch 444\n",
      "Iteration 30200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 445\n",
      "Iteration 30300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 446\n",
      "Starting epoch 447\n",
      "Iteration 30400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 448\n",
      "Iteration 30500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 449\n",
      "Starting epoch 450\n",
      "Iteration 30600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 451\n",
      "Iteration 30700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 452\n",
      "Iteration 30800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 453\n",
      "Starting epoch 454\n",
      "Iteration 30900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 455\n",
      "Iteration 31000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 456\n",
      "Starting epoch 457\n",
      "Iteration 31100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 458\n",
      "Iteration 31200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 459\n",
      "Starting epoch 460\n",
      "Iteration 31300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 461\n",
      "Iteration 31400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 462\n",
      "Starting epoch 463\n",
      "Iteration 31500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 464\n",
      "Iteration 31600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 465\n",
      "Starting epoch 466\n",
      "Iteration 31700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 467\n",
      "Iteration 31800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 468\n",
      "Starting epoch 469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 31900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 470\n",
      "Iteration 32000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 471\n",
      "Starting epoch 472\n",
      "Iteration 32100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 473\n",
      "Iteration 32200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 474\n",
      "Starting epoch 475\n",
      "Iteration 32300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 476\n",
      "Iteration 32400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 477\n",
      "Iteration 32500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 478\n",
      "Starting epoch 479\n",
      "Iteration 32600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 480\n",
      "Iteration 32700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 481\n",
      "Starting epoch 482\n",
      "Iteration 32800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 483\n",
      "Iteration 32900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 484\n",
      "Starting epoch 485\n",
      "Iteration 33000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 486\n",
      "Iteration 33100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 487\n",
      "Starting epoch 488\n",
      "Iteration 33200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 489\n",
      "Iteration 33300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 490\n",
      "Starting epoch 491\n",
      "Iteration 33400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 492\n",
      "Iteration 33500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 493\n",
      "Starting epoch 494\n",
      "Iteration 33600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 495\n",
      "Iteration 33700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 496\n",
      "Starting epoch 497\n",
      "Iteration 33800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 498\n",
      "Iteration 33900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 499\n",
      "Starting epoch 500\n",
      "Iteration 34000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 501\n",
      "Iteration 34100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 502\n",
      "Iteration 34200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 503\n",
      "Starting epoch 504\n",
      "Iteration 34300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 505\n",
      "Iteration 34400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 506\n",
      "Starting epoch 507\n",
      "Iteration 34500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 508\n",
      "Iteration 34600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 509\n",
      "Starting epoch 510\n",
      "Iteration 34700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 511\n",
      "Iteration 34800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 512\n",
      "Starting epoch 513\n",
      "Iteration 34900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 514\n",
      "Iteration 35000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 515\n",
      "Starting epoch 516\n",
      "Iteration 35100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 517\n",
      "Iteration 35200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 518\n",
      "Starting epoch 519\n",
      "Iteration 35300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 520\n",
      "Iteration 35400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 521\n",
      "Starting epoch 522\n",
      "Iteration 35500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 523\n",
      "Iteration 35600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 524\n",
      "Starting epoch 525\n",
      "Iteration 35700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 526\n",
      "Iteration 35800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 527\n",
      "Iteration 35900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 528\n",
      "Starting epoch 529\n",
      "Iteration 36000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 530\n",
      "Iteration 36100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 531\n",
      "Starting epoch 532\n",
      "Iteration 36200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 533\n",
      "Iteration 36300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 534\n",
      "Starting epoch 535\n",
      "Iteration 36400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 536\n",
      "Iteration 36500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 537\n",
      "Starting epoch 538\n",
      "Iteration 36600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 539\n",
      "Iteration 36700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 540\n",
      "Starting epoch 541\n",
      "Iteration 36800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 542\n",
      "Iteration 36900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 543\n",
      "Starting epoch 544\n",
      "Iteration 37000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 545\n",
      "Iteration 37100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 546\n",
      "Starting epoch 547\n",
      "Iteration 37200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 548\n",
      "Iteration 37300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 549\n",
      "Starting epoch 550\n",
      "Iteration 37400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 551\n",
      "Iteration 37500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 552\n",
      "Iteration 37600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 553\n",
      "Starting epoch 554\n",
      "Iteration 37700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 555\n",
      "Iteration 37800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 556\n",
      "Starting epoch 557\n",
      "Iteration 37900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 558\n",
      "Iteration 38000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 559\n",
      "Starting epoch 560\n",
      "Iteration 38100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 561\n",
      "Iteration 38200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 562\n",
      "Starting epoch 563\n",
      "Iteration 38300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 564\n",
      "Iteration 38400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 565\n",
      "Starting epoch 566\n",
      "Iteration 38500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 567\n",
      "Iteration 38600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 568\n",
      "Starting epoch 569\n",
      "Iteration 38700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 570\n",
      "Iteration 38800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 571\n",
      "Starting epoch 572\n",
      "Iteration 38900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 573\n",
      "Iteration 39000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 574\n",
      "Starting epoch 575\n",
      "Iteration 39100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 576\n",
      "Iteration 39200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 577\n",
      "Iteration 39300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 578\n",
      "Starting epoch 579\n",
      "Iteration 39400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 580\n",
      "Iteration 39500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 581\n",
      "Starting epoch 582\n",
      "Iteration 39600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 583\n",
      "Iteration 39700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 584\n",
      "Starting epoch 585\n",
      "Iteration 39800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 586\n",
      "Iteration 39900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 587\n",
      "Starting epoch 588\n",
      "Iteration 40000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 589\n",
      "Iteration 40100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 590\n",
      "Starting epoch 591\n",
      "Iteration 40200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 592\n",
      "Iteration 40300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 593\n",
      "Starting epoch 594\n",
      "Iteration 40400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 595\n",
      "Iteration 40500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 596\n",
      "Starting epoch 597\n",
      "Iteration 40600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 598\n",
      "Iteration 40700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 599\n",
      "Starting epoch 600\n",
      "Iteration 40800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 601\n",
      "Iteration 40900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 602\n",
      "Iteration 41000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 603\n",
      "Starting epoch 604\n",
      "Iteration 41100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 605\n",
      "Iteration 41200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 606\n",
      "Starting epoch 607\n",
      "Iteration 41300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 608\n",
      "Iteration 41400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 609\n",
      "Starting epoch 610\n",
      "Iteration 41500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 611\n",
      "Iteration 41600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 612\n",
      "Starting epoch 613\n",
      "Iteration 41700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 614\n",
      "Iteration 41800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 615\n",
      "Starting epoch 616\n",
      "Iteration 41900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 617\n",
      "Iteration 42000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 618\n",
      "Starting epoch 619\n",
      "Iteration 42100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 620\n",
      "Iteration 42200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 621\n",
      "Starting epoch 622\n",
      "Iteration 42300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 623\n",
      "Iteration 42400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 625\n",
      "Iteration 42500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 626\n",
      "Iteration 42600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 627\n",
      "Iteration 42700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 628\n",
      "Starting epoch 629\n",
      "Iteration 42800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 630\n",
      "Iteration 42900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 631\n",
      "Starting epoch 632\n",
      "Iteration 43000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 633\n",
      "Iteration 43100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 634\n",
      "Starting epoch 635\n",
      "Iteration 43200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 636\n",
      "Iteration 43300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 637\n",
      "Starting epoch 638\n",
      "Iteration 43400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 639\n",
      "Iteration 43500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 640\n",
      "Starting epoch 641\n",
      "Iteration 43600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 642\n",
      "Iteration 43700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 643\n",
      "Starting epoch 644\n",
      "Iteration 43800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 645\n",
      "Iteration 43900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 646\n",
      "Starting epoch 647\n",
      "Iteration 44000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 648\n",
      "Iteration 44100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 649\n",
      "Starting epoch 650\n",
      "Iteration 44200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 651\n",
      "Iteration 44300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 652\n",
      "Iteration 44400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 653\n",
      "Starting epoch 654\n",
      "Iteration 44500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 655\n",
      "Iteration 44600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 656\n",
      "Starting epoch 657\n",
      "Iteration 44700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 658\n",
      "Iteration 44800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 659\n",
      "Starting epoch 660\n",
      "Iteration 44900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 661\n",
      "Iteration 45000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 662\n",
      "Starting epoch 663\n",
      "Iteration 45100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 664\n",
      "Iteration 45200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 665\n",
      "Starting epoch 666\n",
      "Iteration 45300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 667\n",
      "Iteration 45400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 668\n",
      "Starting epoch 669\n",
      "Iteration 45500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 670\n",
      "Iteration 45600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 671\n",
      "Starting epoch 672\n",
      "Iteration 45700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 673\n",
      "Iteration 45800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 674\n",
      "Starting epoch 675\n",
      "Iteration 45900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 676\n",
      "Iteration 46000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 677\n",
      "Iteration 46100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 678\n",
      "Starting epoch 679\n",
      "Iteration 46200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 680\n",
      "Iteration 46300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 681\n",
      "Starting epoch 682\n",
      "Iteration 46400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 683\n",
      "Iteration 46500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 684\n",
      "Starting epoch 685\n",
      "Iteration 46600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 686\n",
      "Iteration 46700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 687\n",
      "Starting epoch 688\n",
      "Iteration 46800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 689\n",
      "Iteration 46900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 690\n",
      "Starting epoch 691\n",
      "Iteration 47000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 692\n",
      "Iteration 47100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 693\n",
      "Starting epoch 694\n",
      "Iteration 47200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 695\n",
      "Iteration 47300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 696\n",
      "Starting epoch 697\n",
      "Iteration 47400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 698\n",
      "Iteration 47500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 699\n",
      "Starting epoch 700\n",
      "Iteration 47600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 701\n",
      "Iteration 47700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 702\n",
      "Iteration 47800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 703\n",
      "Starting epoch 704\n",
      "Iteration 47900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 705\n",
      "Iteration 48000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 706\n",
      "Starting epoch 707\n",
      "Iteration 48100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 708\n",
      "Iteration 48200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 709\n",
      "Starting epoch 710\n",
      "Iteration 48300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 711\n",
      "Iteration 48400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 712\n",
      "Starting epoch 713\n",
      "Iteration 48500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 714\n",
      "Iteration 48600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 715\n",
      "Starting epoch 716\n",
      "Iteration 48700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 717\n",
      "Iteration 48800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 718\n",
      "Starting epoch 719\n",
      "Iteration 48900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 720\n",
      "Iteration 49000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 721\n",
      "Starting epoch 722\n",
      "Iteration 49100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 723\n",
      "Iteration 49200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 724\n",
      "Starting epoch 725\n",
      "Iteration 49300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 726\n",
      "Iteration 49400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 727\n",
      "Iteration 49500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 728\n",
      "Starting epoch 729\n",
      "Iteration 49600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 730\n",
      "Iteration 49700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 731\n",
      "Starting epoch 732\n",
      "Iteration 49800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 733\n",
      "Iteration 49900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 734\n",
      "Starting epoch 735\n",
      "Iteration 50000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 736\n",
      "Iteration 50100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 737\n",
      "Starting epoch 738\n",
      "Iteration 50200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 739\n",
      "Iteration 50300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 740\n",
      "Starting epoch 741\n",
      "Iteration 50400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 742\n",
      "Iteration 50500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 743\n",
      "Starting epoch 744\n",
      "Iteration 50600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 745\n",
      "Iteration 50700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 746\n",
      "Starting epoch 747\n",
      "Iteration 50800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 748\n",
      "Iteration 50900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 749\n",
      "Starting epoch 750\n",
      "Iteration 51000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 751\n",
      "Iteration 51100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 752\n",
      "Iteration 51200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 753\n",
      "Starting epoch 754\n",
      "Iteration 51300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 755\n",
      "Iteration 51400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 756\n",
      "Starting epoch 757\n",
      "Iteration 51500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 758\n",
      "Iteration 51600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 759\n",
      "Starting epoch 760\n",
      "Iteration 51700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 761\n",
      "Iteration 51800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 762\n",
      "Starting epoch 763\n",
      "Iteration 51900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 764\n",
      "Iteration 52000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 765\n",
      "Starting epoch 766\n",
      "Iteration 52100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 767\n",
      "Iteration 52200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 768\n",
      "Starting epoch 769\n",
      "Iteration 52300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 770\n",
      "Iteration 52400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 771\n",
      "Starting epoch 772\n",
      "Iteration 52500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 773\n",
      "Iteration 52600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 774\n",
      "Starting epoch 775\n",
      "Iteration 52700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 776\n",
      "Iteration 52800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 777\n",
      "Iteration 52900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 778\n",
      "Starting epoch 779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 53000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 780\n",
      "Iteration 53100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 781\n",
      "Starting epoch 782\n",
      "Iteration 53200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 783\n",
      "Iteration 53300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 784\n",
      "Starting epoch 785\n",
      "Iteration 53400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 786\n",
      "Iteration 53500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 787\n",
      "Starting epoch 788\n",
      "Iteration 53600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 789\n",
      "Iteration 53700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 790\n",
      "Starting epoch 791\n",
      "Iteration 53800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 792\n",
      "Iteration 53900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 793\n",
      "Starting epoch 794\n",
      "Iteration 54000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 795\n",
      "Iteration 54100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 796\n",
      "Starting epoch 797\n",
      "Iteration 54200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 798\n",
      "Iteration 54300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 799\n",
      "Starting epoch 800\n",
      "Iteration 54400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 801\n",
      "Iteration 54500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 802\n",
      "Iteration 54600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 803\n",
      "Starting epoch 804\n",
      "Iteration 54700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 805\n",
      "Iteration 54800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 806\n",
      "Starting epoch 807\n",
      "Iteration 54900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 808\n",
      "Iteration 55000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 809\n",
      "Starting epoch 810\n",
      "Iteration 55100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 811\n",
      "Iteration 55200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 812\n",
      "Starting epoch 813\n",
      "Iteration 55300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 814\n",
      "Iteration 55400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 815\n",
      "Starting epoch 816\n",
      "Iteration 55500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 817\n",
      "Iteration 55600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 818\n",
      "Starting epoch 819\n",
      "Iteration 55700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 820\n",
      "Iteration 55800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 821\n",
      "Starting epoch 822\n",
      "Iteration 55900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 823\n",
      "Iteration 56000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 824\n",
      "Starting epoch 825\n",
      "Iteration 56100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 826\n",
      "Iteration 56200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 827\n",
      "Iteration 56300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 828\n",
      "Starting epoch 829\n",
      "Iteration 56400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 830\n",
      "Iteration 56500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 831\n",
      "Starting epoch 832\n",
      "Iteration 56600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 833\n",
      "Iteration 56700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 834\n",
      "Starting epoch 835\n",
      "Iteration 56800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 836\n",
      "Iteration 56900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 837\n",
      "Starting epoch 838\n",
      "Iteration 57000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 839\n",
      "Iteration 57100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 840\n",
      "Starting epoch 841\n",
      "Iteration 57200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 842\n",
      "Iteration 57300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 843\n",
      "Starting epoch 844\n",
      "Iteration 57400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 845\n",
      "Iteration 57500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 846\n",
      "Starting epoch 847\n",
      "Iteration 57600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 848\n",
      "Iteration 57700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 849\n",
      "Starting epoch 850\n",
      "Iteration 57800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 851\n",
      "Iteration 57900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 852\n",
      "Iteration 58000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 853\n",
      "Starting epoch 854\n",
      "Iteration 58100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 855\n",
      "Iteration 58200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 856\n",
      "Starting epoch 857\n",
      "Iteration 58300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 858\n",
      "Iteration 58400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 859\n",
      "Starting epoch 860\n",
      "Iteration 58500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 861\n",
      "Iteration 58600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 862\n",
      "Starting epoch 863\n",
      "Iteration 58700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 864\n",
      "Iteration 58800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 865\n",
      "Starting epoch 866\n",
      "Iteration 58900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 867\n",
      "Iteration 59000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 868\n",
      "Starting epoch 869\n",
      "Iteration 59100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 870\n",
      "Iteration 59200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 871\n",
      "Starting epoch 872\n",
      "Iteration 59300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 873\n",
      "Iteration 59400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 874\n",
      "Starting epoch 875\n",
      "Iteration 59500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 876\n",
      "Iteration 59600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 877\n",
      "Iteration 59700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 878\n",
      "Starting epoch 879\n",
      "Iteration 59800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 880\n",
      "Iteration 59900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 881\n",
      "Starting epoch 882\n",
      "Iteration 60000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 883\n",
      "Iteration 60100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 884\n",
      "Starting epoch 885\n",
      "Iteration 60200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 886\n",
      "Iteration 60300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 887\n",
      "Starting epoch 888\n",
      "Iteration 60400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 889\n",
      "Iteration 60500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 890\n",
      "Starting epoch 891\n",
      "Iteration 60600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 892\n",
      "Iteration 60700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 893\n",
      "Starting epoch 894\n",
      "Iteration 60800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 895\n",
      "Iteration 60900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 896\n",
      "Starting epoch 897\n",
      "Iteration 61000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 898\n",
      "Iteration 61100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 899\n",
      "Starting epoch 900\n",
      "Iteration 61200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 901\n",
      "Iteration 61300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 902\n",
      "Iteration 61400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 903\n",
      "Starting epoch 904\n",
      "Iteration 61500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 905\n",
      "Iteration 61600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 906\n",
      "Starting epoch 907\n",
      "Iteration 61700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 908\n",
      "Iteration 61800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 909\n",
      "Starting epoch 910\n",
      "Iteration 61900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 911\n",
      "Iteration 62000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 912\n",
      "Starting epoch 913\n",
      "Iteration 62100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 914\n",
      "Iteration 62200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 915\n",
      "Starting epoch 916\n",
      "Iteration 62300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 917\n",
      "Iteration 62400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 918\n",
      "Starting epoch 919\n",
      "Iteration 62500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 920\n",
      "Iteration 62600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 921\n",
      "Starting epoch 922\n",
      "Iteration 62700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 923\n",
      "Iteration 62800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 924\n",
      "Starting epoch 925\n",
      "Iteration 62900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 926\n",
      "Iteration 63000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 927\n",
      "Iteration 63100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 928\n",
      "Starting epoch 929\n",
      "Iteration 63200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 930\n",
      "Iteration 63300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 931\n",
      "Starting epoch 932\n",
      "Iteration 63400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 933\n",
      "Iteration 63500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 935\n",
      "Iteration 63600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 936\n",
      "Iteration 63700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 937\n",
      "Starting epoch 938\n",
      "Iteration 63800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 939\n",
      "Iteration 63900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 940\n",
      "Starting epoch 941\n",
      "Iteration 64000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 942\n",
      "Iteration 64100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 943\n",
      "Starting epoch 944\n",
      "Iteration 64200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 945\n",
      "Iteration 64300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 946\n",
      "Starting epoch 947\n",
      "Iteration 64400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 948\n",
      "Iteration 64500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 949\n",
      "Starting epoch 950\n",
      "Iteration 64600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 951\n",
      "Iteration 64700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 952\n",
      "Iteration 64800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 953\n",
      "Starting epoch 954\n",
      "Iteration 64900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 955\n",
      "Iteration 65000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 956\n",
      "Starting epoch 957\n",
      "Iteration 65100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 958\n",
      "Iteration 65200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 959\n",
      "Starting epoch 960\n",
      "Iteration 65300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 961\n",
      "Iteration 65400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 962\n",
      "Starting epoch 963\n",
      "Iteration 65500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 964\n",
      "Iteration 65600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 965\n",
      "Starting epoch 966\n",
      "Iteration 65700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 967\n",
      "Iteration 65800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 968\n",
      "Starting epoch 969\n",
      "Iteration 65900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 970\n",
      "Iteration 66000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 971\n",
      "Starting epoch 972\n",
      "Iteration 66100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 973\n",
      "Iteration 66200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 974\n",
      "Starting epoch 975\n",
      "Iteration 66300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 976\n",
      "Iteration 66400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 977\n",
      "Iteration 66500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 978\n",
      "Starting epoch 979\n",
      "Iteration 66600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 980\n",
      "Iteration 66700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 981\n",
      "Starting epoch 982\n",
      "Iteration 66800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 983\n",
      "Iteration 66900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 984\n",
      "Starting epoch 985\n",
      "Iteration 67000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 986\n",
      "Iteration 67100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 987\n",
      "Starting epoch 988\n",
      "Iteration 67200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 989\n",
      "Iteration 67300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 990\n",
      "Starting epoch 991\n",
      "Iteration 67400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 992\n",
      "Iteration 67500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 993\n",
      "Starting epoch 994\n",
      "Iteration 67600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 995\n",
      "Iteration 67700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 996\n",
      "Starting epoch 997\n",
      "Iteration 67800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 998\n",
      "Iteration 67900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 999\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "def model_init_fn(inputs, is_training):\n",
    "    input_shape = (80, 100, 1)\n",
    "    hidden_layer_size, num_classes = 2000, 1\n",
    "    initializer = tf.variance_scaling_initializer(scale=2.0)\n",
    "    layers = [\n",
    "        tf.layers.Flatten(input_shape=input_shape),\n",
    "        #tf.layers.Dense(hidden_layer_size, activation=tf.nn.relu,\n",
    "        #                kernel_initializer=initializer),\n",
    "        tf.layers.Dense(num_classes, kernel_initializer=initializer),\n",
    "    ]\n",
    "    model = tf.keras.Sequential(layers)\n",
    "    return model(inputs)\n",
    "\n",
    "def optimizer_init_fn():\n",
    "    return tf.train.GradientDescentOptimizer(learning_rate)\n",
    "\n",
    "train_part34(model_init_fn, optimizer_init_fn, num_epochs=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resize and process raw images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#folder = 'C:\\\\Users\\\\Sur lab\\\\Documents\\\\allenCCF3\\\\Data\\\\MouseC07'\n",
    "folder = 'C:\\\\Users\\\\Sur lab\\\\Dropbox (MIT)\\\\Leica\\\\C07_LMN_092018_disynaptic_STRACC_mCherry_10x'\n",
    "folder2 = 'C:\\\\Users\\\\Sur lab\\Dropbox (MIT)\\\\Leica\\\\C20_LMN_CAVCreRACC_RabiesLACC_112618'\n",
    "#folder = 'C:\\\\Users\\\\Sur lab\\\\Documents\\\\allenCCF3\\\\Data\\\\MouseC07\\\\Raw'\n",
    "files = glob.glob(folder + '\\\\*\\\\*ch00.tif')\n",
    "files2 = glob.glob(folder2 + '\\\\*ch00.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = np.array([0, 2, 4, 6, 8, 10, 1, 3, 5, 7, 9, 11,\n",
    "                 12, 14, 16, 18, 20, 13, 15, 17, 19, 21,\n",
    "                 22, 24, 26, 28, 30, 32, 23, 25, 27, 29, 31, 33,\n",
    "                 34, 38, 42, 46, 50, 51, 52, 53,\n",
    "                 35, 36, 37, 39, 40, 41, 43, 44, 45, 47, 48, 49, 55, 56])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images\n",
    "bad_images = [38, 40, 44, 48, 52, 55, 59, 60, 61, 62]\n",
    "flipped_images = [26, 36, 37, 41, 42, 45, 46, 49, 50, 56, 57]\n",
    "#all_images = np.zeros((51 * 120, 80, 100, 1))\n",
    "naugment = 50\n",
    "imshape = (100, 80)\n",
    "crop_extent = 10\n",
    "\n",
    "count = 0\n",
    "imlst = []\n",
    "for i in range(len(order)):\n",
    "    #print(im.height/40, im.width/40, i)\n",
    "    if order[i] + 1 in bad_images:\n",
    "        continue\n",
    "    \n",
    "    im = Image.open(files[order[i]])\n",
    "    imresize = im.resize(imshape, Image.ANTIALIAS)\n",
    "    \n",
    "    if order[i] + 1 in flipped_images:\n",
    "        imresize = imresize.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "        \n",
    "    # Save image\n",
    "    imresize.save('C07_small/C07_im' + str(i) + '_small.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-17-8d035783d2a5>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-17-8d035783d2a5>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    if order[i] + 1 in flipped_images:\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "imresize = im.resize(imshape, Image.ANTIALIAS)\n",
    "    #imarr = np.array(imresize)\n",
    "    if order[i] + 1 in flipped_images:\n",
    "        imresize = imresize.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "        \n",
    "    # Save image\n",
    "    imresize.save('C07_small/C07_im' + str(i) + '.png')\n",
    "        \n",
    "    # Data augmentation\n",
    "    for i in range(naugment):\n",
    "        # Pick a random angle\n",
    "        angle = np.random.rand() * crop_extent * 2 - crop_extent\n",
    "        ver_crop = np.random.rand() * crop_extent * 2 - crop_extent\n",
    "        hor_crop = np.random.rand() * crop_extent * 2 - crop_extent\n",
    "        \n",
    "        modified1 = imresize.rotate(angle).crop((ver_crop, hor_crop, ver_crop+imshape[0], hor_crop+imshape[1]))\n",
    "        modified2 = modified1.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "        \n",
    "        modified1 = np.array(modified1)[:,:,np.newaxis] / 256\n",
    "        modified2 = np.array(modified2)[:,:,np.newaxis] / 256\n",
    "        \n",
    "        imlst += [modified1, modified2]\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load C20 images\n",
    "naugment = 50\n",
    "imshape = (100, 80)\n",
    "crop_extent = 10\n",
    "\n",
    "count = 0\n",
    "imlst = []\n",
    "for i in range(len(files2)):\n",
    "    print(i)\n",
    "    \n",
    "    im = Image.open(files2[i])\n",
    "    imsave = im.resize(imshape, Image.ANTIALIAS)\n",
    "    imresize = im.resize(imshape, Image.ANTIALIAS)\n",
    "    #imarr = np.array(imresize)\n",
    "    #if order[i] + 1 in flipped_images:\n",
    "    #    imresize = imresize.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "        \n",
    "    # Save image\n",
    "    imsave.save('C20_small/C20_im' + str(i) + '_small.tif')\n",
    "    \n",
    "    imarr = np.array(imresize)[:,:,np.newaxis] / 256\n",
    "    imlst.append(imarr)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Data augmentation\n",
    "    for i in range(naugment):\n",
    "        # Pick a random angle\n",
    "        angle = np.random.rand() * crop_extent * 2 - crop_extent\n",
    "        ver_crop = np.random.rand() * crop_extent * 2 - crop_extent\n",
    "        hor_crop = np.random.rand() * crop_extent * 2 - crop_extent\n",
    "        \n",
    "        modified1 = imresize.rotate(angle).crop((ver_crop, hor_crop, ver_crop+imshape[0], hor_crop+imshape[1]))\n",
    "        modified2 = modified1.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "        \n",
    "        modified1 = np.array(modified1)[:,:,np.newaxis] / 256\n",
    "        modified2 = np.array(modified2)[:,:,np.newaxis] / 256\n",
    "        \n",
    "        imlst += [modified1, modified2]\n",
    "        #print(modified1.shape, modified2.shape)\n",
    "        \n",
    "    #all_images[count] = imarr[:,:,np.newaxis] / 256\n",
    "    \n",
    "    #count += 1\n",
    "    #plt.imshow(imarr, aspect='auto')\n",
    "    #imlst.append(imarr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zcoords = pd.read_csv('human_label_APcoords.csv')\n",
    "zcoords = zcoords[zcoords.AP < 100].AP\n",
    "zcoords = np.array(zcoords).repeat(100)\n",
    "plt.plot(zcoords)\n",
    "#plt.plot(zcoords2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = np.array(imlst)\n",
    "plt.figure(figsize=(20,15))\n",
    "for i in range(38):\n",
    "    plt.subplot(9, 7, i + 1)\n",
    "    plt.imshow(all_images[i,:,:,0], aspect='auto')\n",
    "    \n",
    "zcoords = pd.read_csv('human_label_APcoords_C20.csv')\n",
    "#zcoords = np.linspace(1.98, -2.9, 51)\n",
    "#zcoords = zcoords.repeat(naugment * 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now randomize the array\n",
    "nimages = all_images.shape[0]\n",
    "ntrain = int(nimages * 0.7)\n",
    "nval = int(nimages * 0.2)\n",
    "ntest = nimages - ntrain - nval\n",
    "\n",
    "order = np.arange(nimages)\n",
    "np.random.shuffle(order)\n",
    "\n",
    "shuffled_images = all_images[order]\n",
    "shuffled_coords = zcoords[order]\n",
    "\n",
    "train_images = shuffled_images[:ntrain]\n",
    "train_coords = shuffled_coords[:ntrain]\n",
    "val_images = shuffled_images[ntrain:(ntrain + nval)]\n",
    "val_coords = shuffled_coords[ntrain:(ntrain + nval)]\n",
    "test_images = shuffled_images[ntrain+nval:]\n",
    "test_coords = shuffled_coords[ntrain+nval:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 100)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_aug.shape[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshape = X_test_aug.shape[1:3]\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Conv2D(32, kernel_size=(5,5), strides=(1,1),\n",
    "                            activation='relu', input_shape=(imshape[0],imshape[1],1)))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(keras.layers.Conv2D(64, (5, 5), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data: subtract the mean pixel and divide by std\n",
    "mean_pixel = X_train_aug.mean(axis=(0, 1, 2), keepdims=True)\n",
    "std_pixel = X_train_aug.std(axis=(0, 1, 2), keepdims=True)\n",
    "X_train_aug = (X_train_aug - mean_pixel) / std_pixel\n",
    "X_val_aug = (X_val_aug - mean_pixel) / std_pixel\n",
    "X_test_aug = (X_test_aug - mean_pixel) / std_pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "6800/6800 [==============================] - 51s 7ms/step - loss: 0.2447\n",
      "Epoch 2/4\n",
      "6800/6800 [==============================] - 53s 8ms/step - loss: 0.1643\n",
      "Epoch 3/4\n",
      "6800/6800 [==============================] - 52s 8ms/step - loss: 0.1497\n",
      "Epoch 4/4\n",
      "6800/6800 [==============================] - 51s 7ms/step - loss: 0.1079\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2529566e828>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd = keras.optimizers.SGD(lr=0.1, clipnorm=1.)\n",
    "adagrad = tf.train.AdagradOptimizer(learning_rate=10)\n",
    "adam = tf.train.AdadeltaOptimizer(learning_rate=10)\n",
    "model.compile(optimizer= adam, \n",
    "              loss='mean_squared_error')\n",
    "\n",
    "model.fit(X_train_aug, y_train_aug, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save trained model\n",
    "model.save('brain_slice_model_Adeltagrad.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 3\n",
    "plt.imshow(val_images[id][:,:,0])\n",
    "print('Coords = ', val_coords[id], ', predicted = ', prediction_val[id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_test = model.predict((X_val - mean_pixel) / std_pixel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.10673529328643114"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(X_val_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[8.36831258e-17]]]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16798673502604164"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean((X_val/256 - mean_pixel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2786.485373779769"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean((y_val - prediction_test.T)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6557438524302001"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(0.43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2529622aef0>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_val, prediction_test)\n",
    "plt.plot([-3, 3], [-3, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1ed09cd2cc0>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAHEFJREFUeJzt3X9snHd9B/D3x9cLswurEyUI6sZ1yCAZmRsMpgmyJpTwIx1tggnNoG0YGhPR0JhgFINNoyXVyuLNCJgE0hSg2h/NQpuS3VrSKRQlCC0iWd06rhuSDEJLkmtRzYIBNQdxzp/9YZ9z9/h57p4f3+eeX++XVDV+fL77Jr773Pc+38/38xVVBRERpUdL1AMgIiKzGNiJiFKGgZ2IKGUY2ImIUoaBnYgoZRjYiYhShoGdiChlGNiJiFKGgZ2IKGWui+JBly5dql1dXVE8NBFRYj399NO/VNVljW4XSWDv6urC6OhoFA9NRJRYIvJzN7djKoaIKGUY2ImIUoaBnYgoZRjYiYhShoGdiChlGNiJiFImknJHIqIsKYwVMXL4LF6cKuHG9lYMbFqF/p6O0B6PgZ2IKESFsSKGDk6gNF0GABSnShg6OAEAoQV3pmKIiEI0cvjsfFCvKE2XMXL4bGiPycBORBSiF6dKnq6bwMBORBSiG9tbPV03gYGdiChEA5tWoTWfq7nWms9hYNOq0B6Ti6dERCGqLJCyKoaIKEX6ezpCDeRWTMUQEaUMAzsRUcowsBMRpQwDOxFRynDxlIgoZIntFSMiOQCjAIqqeoep+yUiSrKk94r5FIDTBu+PiCjxEtsrRkRuAnA7gG+auD8iorRIcq+YrwL4HIAZQ/dHRJQKiewVIyJ3AHhZVZ9ucLsdIjIqIqOTk5NBH5aIKBE2rF7m6boJJmbsfQC2iMgLAL4NYKOIPGS9karuVdVeVe1dtiy8vxARUZwcPWM/kXW6bkLgwK6qQ6p6k6p2AfgwgCOquj3wyIiIUqDokEt3um4CNygREaWM0Q1KqvoDAD8weZ9EROQNd54SEQXQ7F2lbjCwExE5aBS0o9hV6gZz7ERENipBuzhVguJa0C6MFedvE8WuUjc4YyeiTLLOxjesXoajZybnv7585apj0K7MxqPYVeoGAzsRZY5dCuWh4+fnv1+vFLE6aN/Y3mp72zB3lbrBVAwRZY5dCsWt9rb8/J8HNq1Caz5X8/3WfA4Dm1YFGl9QnLETUeYESZWoXvtzJSXDqhgioojd0JrHVGna189af66/pyPyQG7FwE5EmSPi/2dzlh/eWZjA/hMXUFZFTgR3rVuOB/q7A44wGAZ2Iko9awXMry77m60DQLkqF7OzMFGz6FpWnf86yuDOxVMiSjW7enRT9p+44Ol6szCwE1GqBamAaaR69u7merMwsBNRqkW9WSgKDOxElGpRbxaKAgM7EaWa3SaitGNVDBHFQljtb+02EYV5elEcMLATUeTi2v42qZiKIaLIhdn+Nsxyx7hiYCeiyIXZ/jbMcse4YiqGiCJnsv2tNVefhRm6FWfsRBQ5U+1vs5h2scPATkSR6+/pwAff1jHfYCsngg++zXvXxCymXewwsBNR5ApjRTz81IX5rfhlVTz81IWa80XdyOoM3YqBnYgid//jpzBdru2vMl1W3P/4KU/3Y22pm1UM7EQUOac2ul7b60bdfCsuWBVDRKnREaMqmL7hI5E1IGNgJ6JY6xo8NP/nvpVLsO/j73C8bdui+CQhonyDic+/AhFRA8fOXcI93/iR4/d/8vIrTRxNfHHGTkRNZ91E5MWxc5dCGlV6BJ6xi8hyETkqIqdF5JSIfMrEwIgonbiJKHwmZuxXAdyrqs+IyGsAPC0iT6rqjw3cNxElTKP2u9xEFL7AgV1VXwLw0tyffysipwF0AGBgJ8qYwlgRA4+Oz9ekF6dKGHh0HMC19rucoYfP6OKpiHQB6AFwwuZ7O0RkVERGJycnTT4sEcWEqY1GFIyxxVMReTWA7wD4tKr+xvp9Vd0LYC8A9Pb2chcBUQqZ2mhUT94yHa1O/dAsI4FdRPKYDer7VPWgifskInPCOnbOC1MbdqZnrv25MFbEZx45iRlOFWsEDuwiIgC+BeC0qn45+JCIyKS4HDsXRm79CwefZVC3YSLH3gfgIwA2isjJuf/eZ+B+icgAp2Pn7n1kHCsGD6Fv+IjnLopxcbl6+k7zTFTF/DcAtlQjiimn9EelYRYPjk4fthQgSjk3OztNHRxN8cDAThRzhbEi+oaP+E6bbFi9zNXtWFWSHuwVQxRjJhY+j55xt2/khta8v0FS7HDGThRjTgufXtImbmfi02UuRKYFZ+xEMeYUlL2kTf4g34KSi+qRV66UsXLoCZRVkRPBXeuW44H+btePQ/HBGTtRjDmlR7ykTX7noSSw+jDph46fx87ChOufpfhgYCeKMaezmb2c2Rxk/85Dx88H+GmKCgM7UYxNOfRYcbpOBDDHThS6IH1a2tvytg202ttYwULOGNgpk5rVFCtoueLvHA6kqFy3+3sAqLnW6nLxNO1yIvMLw5W1hLRiYKfMKYwVMXBgHNMzVYdBHKg9DMKUeuWKbh7LKSCXpmds/x6ffvhkze2KUyXkWtjxAwDO7bnWwqpr8FCEI5nV4fGsVy8Y2Clzdj92aj4YVkzPKHY/dsp4YHcqSyxOlQKXFtr9PeyU2f4wdlrzuflPV2Hg4illzlTJYUHS4XoQ9fq0BC0tDGO81Fh7gB26gtmZ+p6t3aE2XOOMnciBiTz8wKZVNTn2eh46fp4bghLgjrWv9/2zzw/fbnAkzhjYiWyYOpyictvqNwge5pxsbnvvRImpGCIbJnq0UHyYXKhMQhdMztgpcxblBFfKCxcUF+WuVY+Y6NEC2FfgUHOZXqisXjeJa+kkZ+yUOdM2Qd163WnR082hFdXcVq6QeUEXKnMtgrylVNT6JhHHoA5wxk4Z5PRSrL6+YfUy2z4pbg+tqGDlSnSCLlS2APjQrctx9Myk4wJ6R0zXTBjYiWw4LZAlYeGMzJieURw9M4ljgxsdb+Ol6qmZmIohsuE0C4vj7IzC02hNpb+nA3u2dqOjvXU+9RMHnLET2XBaFMt56ZdLiedmTaW/p6MmPROHdgWcsRPZcFoUi+tiGXnjZmYd9rb/MHHGTlSla/AQciK4flEOr1xZmDcN+6O2tX8M1Xddi+CqTdXRdQ0an9nlxvM5wfWLrsOvS9OhdvxsBgZ2IouyKl65UkauRWoaaLmdwd3zjR/h2LlLvh+78n+eXmSvLX8t0fClbWvxdw+frKlokrnr9djtCDYVyNvyLbhs05WzetxhY2AncmDtivjWzhsavvCDBHVy51X53PyfgwRoa27clH/cegs+88hJVD99WmT2erMwsBO5dOzcJewsTNRt1MWgHj7riVJhBWi/wvw04BYDO5EH+9iBMXJJqEyK+s3GSGAXkdsA/AuAHIBvquqwifslihvWxNTntOhskrUyqVnHHCZJ4MAuIjkAXwfwHgAXATwlIo+p6o+D3jcRJcvlkIM6UFuZZKq9ctqYmLHfCuCnqvozABCRbwN4PwAGdko962wx60z2m8+3CCC1zdmslUlBz5RNKxOBvQPAhaqvLwJYZ+B+iRqK8mO43Wwx65yap7nV0d5a87sE6i9CmmqvnDYmArvdSsaCVKSI7ACwAwA6OzsNPCxlXdQfw+1mi1n33fGXfP9sW77FtuFWvd+l0yeErH96MlExfxFA9Ra5mwC8aL2Rqu5V1V5V7V22zFvrU5pVGCuib/gIVgweQt/wERTGilEPKVJRnXLUNXgIXYOHOEO3EaRNcclmU08jA5tWobWqrh1IdisAU0zM2J8C8EYRWQGgCODDAO42cL9UJerZqWkmUij8GJ4ufiqO4lAzHkeBA7uqXhWRTwI4jNlyxwdV9VTgkVGNNC0SmXqT4sfw+Fncll+wgShsUdeMx5GR5gWq+oSqvklVV6rqF03cJ9VK0+zUVAqFH8PD57Xp2a7Na5DP+dtA1MxeKmnHf8mEMHUGZxyYOsTC7pADv+dbZl0+1/h8Tzf6ezowcufamt/J9vWdDYN9s3uppB1bCiSEXZtRuxdeEnbhCezzqfHfKB6NfIuEdiC2APPPkwOj52t63bhpembHLjXSe/OSmuflhtXL6p4lWpGE53McMbAnhJtFoiC562a+gNwcJu1G2haUnYxsW4uRw2dDqcKpHPi8szCxoIGZm6ZnfvXevKTh/Wbl9xsGpmISpL+nA8cGN+L54dtxbHDjgie339x15QVUnCpBce0FFPdyyqjKHZut8nsP0/4TFzxd98Lv8ysrv98wMLCniN8F1qS+gNK0oByW7evdbQYM8yhAv88v/n79Y2BPEb8LrKYWM5vNKSfPXP1sa9vt6ztdp1GcWuGaaJHr9/mVpoKBZmNg9yDuOz+zVv7ntE+x0f7F6xflGtwiuVrzOXz1Q2/BuT3v85Qbdzpf1cS5q37fNLL2fDaJi6cuhb2QY128dFs1UI278Nz54ge6ce+B8QVH3yVZdXWLn9935U1g/4kLNYdpm1g49Zvm4fPZPwZ2l8Lc+Wn3plHdIa/yJjL680sNgz134TVmDRhpCO+V6hY77a152x4u7a35mq8f6O8OpQKmw2GHsJvNT3w++8NUjEthLuS46RJYmi5j3/HziatciavqCqO0u2Pt6z1dN40pleZjYHcpzIUct28O1pllEipXKHpHz0x6um4adwg3H1MxLrnd+elHkFNn4l65QtGLQ9kgUyrNxcDuUpgLOXZvGm5ZKwuavQV7Z2EilAU3ModdMLOHgd2DsGYdQRbzqisLCmNFDDw6Pn9GZHGqhIFHx2sew6u+4SOObxI7CxM1i7xl1fmvGdzNu35RDq/YHBbdqHwzzE+bFE/MsceEicW8+x8/VXPwLzB7EPD9j/tvj19vsdbvNvQWh/Jlp+s0yy6o17tewRx39nDGniJOBxyYOvjAWt7ptz7ZqXw8RWXlociJ2P7butkdyhx3tjCwRyDJrUi5WBudMPu5ULowsDdZYayIgQPj8/21i1MlDBwYx4HR8zj+s18FepG63YgShIneIeRPkI0+lC3MsTfZ7sdOLTg0YXpGcezcpcAzr91b1iw4BSffIti9ZU2g+63G2aG9Su7a5JuoFTf6kFucsTeZ3YzaFPbWiE5l0dvaHsIk/n7JLQZ2IoPC7kPDRVByI5OB3e/ipYlFT6daZBN4lFg8VAffrsFDEY+GsihzOXa/x3SZOj4unwvvnzypJyERkVmZm7H7bb9rqm3vr0PMsbvtCWL95JF1TtVEccAiJPIjczN2vw2RTDVSagvx9B6n+66+Xhgr4jMPn6z55JF1dtVEpgQNzCxCIj8yF9j9tt811bY3rPx6vfuuvj508NmGR8dlTX9PB0a2ra3Zcm/KPevcHSZNZFLmArvfWuANq5d5uh5XpWmGdTvVvXqODW709LOL25xr1x/o78b29Z3zG7tyImjLZ+5lR02WuRy731rg746/5Hg96k6GK4ee4MahgPyuO+Rzgl2b628Asx45Z+2KSWRaoMAuIiMANgO4AuAcgL9U1SkTAwuTn1pgp8U1N4tu1UEjDAzqwdiViTrJtwCv/cPWQCWvXk4uWpTj6il5F3TG/iSAIVW9KiL/BGAIwOeDDys9wtyJSGa4OXO2YnoGnlM1Vl7e4P/87csDPRZlU6DArqrfq/ryOIA7gw0nfbwEjWbICVDmBL+Gl0ArqH/4iBtejkJs1rmklC4mV3E+BuC/DN5fKjTzXEk3rgtxg1RSecmpV0pEg2xSs1vAdxK35w8lQ8NXuYh8X0Ses/nv/VW3uQ/AVQD76tzPDhEZFZHRycloZyGFsSL6ho9gxeAh9A0f8fzC9KI1ZhUQv7/Kqhgru0DrNrPtZ2ev3YlGTl0huYGM/GiYilHVd9f7voh8FMAdAN6l6ryKp6p7AewFgN7e3siSAWGcC1rP5ZiUF7JyxpldpdSG1cvwnaeLrtJofmbV1gV8u7UYtuQlv4JWxdyG2cXSd6rqZTNDCle9c0HT3CiLQb0+u0qp3puX1AT7y1eu2h4z6GdWbddQbs/WbrbkJSOCVsV8DcCrADwpsxswjqvqXwceVYjcngvKfioU1qza6VPjyJ1rA1fcEAHBq2L+yNRA4sTuhUdk6qCLrH5qpObJ3M5TN+xeeLRQTsQ2xZPmc1FNHHTh9lMjkV/xKtmICb7A3Llrnf3mGafrRNQcDOzkm12Dq+3rOyPvnRN3TqWNYR6ETdnCVIyNOB+8EDfWBlfU2O4tazBwYBzTM9fSWPkWwe4t9ZuJEbnFGbuNMA9eILLr/z6ybS0XTskYztht2FU/sDKGTDKxCEvkJHWBfWdhAvtPXEBZFTkR3LVuua9UgfWFx9PmzVnclrddoK53YAURuZeqwG49wKCsOv+11+DODUrh2bV5Tc0+AcDdgRVWTmshXISkrEtVjn3/iQuerjspjBUxcGCcBz6HpL+nAyN3WnLMd3rPMduthXARkihlM3anfihe+6TsfuxUTcUCmWcix2xqJyhR2qQqsJvaCclSx+TgIiTRQokK7HYd8apf1OvfsBjHzl1a8HPr37C4mcMkIopUYgK73YHDQwcnAFz7SP7C/9nnwp2uExGlUWIWT+3ODrWeXuO0yMnFTyLKksQEdqdTaqqvO+XS09xtkIjIKjGB3amWvPq6qaoYIqIkS0xgtztwmGdCEhEtlJjA3t/Tgbd23lBz7a2dN7DUjYjIIjGBfWdhYkEp47Fzl7CzMBHRiNKlb+WSmp2gRJRciSl3rNcugP3A/XNqlMamZ0TJlZjAzoVR814Yvj3qIRBRCBKTiiHzVgweQt/wERTGilEPhYgMYmDPsErnyqGDEwzuRCmSmMDOA4DDY93BCwBOe7q414so/hIT2C9fuerpOnlj3dl7z7pO29s5XSei+EhMYL9Stl8kdbpO3lh39vbevMT2dk7XiSg+EhPYKTx2O3h3P3bK9rZO14koPhjYU6CyscirymakPVu7F+zgdTpshIeQEMVfYurY00gwmwIJ0la4b+US7Pv4OwAAK4ee8FTX/zzr2IlSyciMXUQ+KyIqIktN3F9WPD98O44Nbgx0H9t6ry1mmtystbjNvtrI6ToRxUfgwC4iywG8B8D54MMhr6rLFE32eNm1eQ1yLbUJnlyLYNfmNcYeg4jCYWLG/hUAn8PsfhfyoLLzM4jqNI5da+MgrE8OLsgQJUOg16qIbAFQVNVxF7fdISKjIjI6OTkZ5GFjJch+ncrOT1P6ezqwZ2u3qy6NLQ0GPnL4LKZnat+rp2d0wUYmIoqfhounIvJ9AK+z+dZ9AL4A4L1uHkhV9wLYCwC9vb2pmd3H7S/S39NRU+GyszCBh44vzJLd3WCjkZujCIkonhoGdlV9t911EekGsALAuMzuM78JwDMicquq/sLoKMm3Sjve/ScuoKzq2KbXyqlax+mIQiKKD9/ljqo6AeC1la9F5AUAvar6SwPjSoy2fPwzzw/0d3vuWT+waRWGDk6gNF2ev8ajCImSgXXsAcUtFWNKJZ0zcvgsXpwq4cb2VgxsWsWjCIkSwFhgV9UuU/eVJKXpGd8/a2KDUpjdLa35eiJKhvjnEVKsskHJ76affItg9xbWlRNRrcwF9pxDQ3Gn642Y2Im5a/Ma5HPuHr+6lHFk21rOqIlogczl2E2fnXr7La8PMhwAC/PZ9UYStAUBEaVf5mbsTpt2/G7HP/TsS0GGM6+/pwPHBjeyMRcRBZa5wG637T5IGd+vLrONLRHFS+ZSMSzjI6K0y1xgB8yW8fEwbSKKm8ylYkxiuSERxREDuw2nWXhbvoXlhkQUe5lMxTTiVNL+qnyO5YZEFHucsduYcqh0cbpORBQnqQrsixx2bzpdd+LUmpYta4koCVIV2P/5zrULTjSSuetemK51JyJqplTl2E3VqLPWnYiSLFWBHTBXo86WtUSUVKlKxRAREQN7LDm1AjbRIpiI0o+BPYbs+rPnc4Jdm7nLlYgaS12OPQ24eEtEQTCwh6y9NY+p0sKNTY2ah3Hxloj8YmB3UBgrGpkxT5ftD7t2uk5EFBQDu43CWBFDBydQmi4DAIpTJQwdnAAAz8H9lStlT9eJiIJKzOJpi0NXAKfrQYwcPjsf1CtK02WMHD5r/sGIiAxLTGC/e12np+tBvDhV8nS9Hqf3nRDej4iIACQosPfevGTBYFvmrptmsgmYerxORBRUYgL7yOGzsC43zsxdN81kEzCn6hceqUdEYUnM4mnRIQ3idD0Ik3XkTod2OF0nIgoqMYE9J4KyLkxg5EKKkKbqyHloBxE1W+BUjIj8rYicFZFTIvLPJgZlxy6o17seFzy0g4iaLVBgF5ENAN4P4BZVXQPgS0ZGZaPDIRA6XY8LHtpBRM0WdMb+CQDDqvp7AFDVl4MPyV5SA2R/Twf2bO1GR3srBLNvRHu2drNdABGFJmiO/U0A/lREvgjgdwA+q6pPBR/WQklujMW+L0TUTA0Du4h8H8DrbL5139zPLwawHsDbATwiIm9QXZj4FpEdAHYAQGenv01FDJBERI01DOyq+m6n74nIJwAcnAvk/yMiMwCWApi0uZ+9APYCQG9vb7xXPImIEixojr0AYCMAiMibACwC8MuggyIiIv+C5tgfBPCgiDwH4AqAj9qlYYiIqHkCBXZVvQJgu6GxEBGRAYnpFUNERO5IFJkTEZkE8HODd7kUycztc9zNxXE3F8dt3s2quqzRjSIJ7KaJyKiq9kY9Dq847ubiuJuL444OUzFERCnDwE5ElDJpCex7ox6ATxx3c3HczcVxRyQVOXYiIromLTN2IiKak7rALiKfFREVkaVRj8UNEfkHEXlWRE6KyPdE5Maox+SGiIyIyJm5sf+HiLRHPSY3RGTb3KEwMyIS+8oHEblt7iCbn4rIYNTjcUNEHhSRl+d2pCeGiCwXkaMicnruOfKpqMfkV6oCu4gsB/AeAOejHosHI6p6i6q+BcB3Afx91ANy6UkAf6KqtwD4XwBDEY/HrecAbAXww6gH0oiI5AB8HcCfAXgzgLtE5M3RjsqVfwNwW9SD8OEqgHtV9Y8x27H2bxLy771AqgI7gK8A+ByAxCwcqOpvqr68HgkZu6p+T1Wvzn15HMBNUY7HLVU9rapnox6HS7cC+Kmq/myufce3MXtiWayp6g8BXIp6HF6p6kuq+szcn38L4DSARPYJT8xh1o2IyBYARVUdl5AOuA7L3EElfwHg1wA2RDwcPz4G4OGoB5FCHQAuVH19EcC6iMaSKSLSBaAHwIloR+JPogJ7g0M/vgDgvc0dkTv1xq2q/6mq9wG4T0SGAHwSwK6mDtBBo3HP3eY+zH6E3dfMsdXjZtwJYTdDScQnuiQTkVcD+A6AT1s+USdGogK706EfItINYAWAymz9JgDPiMitqvqLJg7RVr3DSiz+HcAhxCSwNxq3iHwUwB0A3hWnds0e/r3j7iKA5VVf3wTgxYjGkgkiksdsUN+nqgejHo9fiQrsTlR1AsBrK1+LyAsAelU1ro185onIG1X1J3NfbgFwJsrxuCUitwH4PIB3qurlqMeTUk8BeKOIrABQBPBhAHdHO6T0ktlZ4bcAnFbVL0c9niDStniaRMMi8pyIPIvZVFJSSqy+BuA1AJ6cK9X816gH5IaIfEBELgJ4B4BDInI46jE5mVuc/iSAw5hdyHtEVU9FO6rGRGQ/gB8BWCUiF0Xkr6Iek0t9AD4CYOPcc/qkiLwv6kH5wZ2nREQpwxk7EVHKMLATEaUMAzsRUcowsBMRpQwDOxFRyjCwExGlDAM7EVHKMLATEaXM/wOFPpr7EkGqOQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_train_aug, prediction_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zcoords.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(train_images)\n",
    "\n",
    "\n",
    "plt.scatter(train_coords, prediction)\n",
    "\n",
    "#prediction_val = model.predict(val_images)\n",
    "#plt.scatter(val_coords, prediction_val, alpha=0.5)\n",
    "\n",
    "plt.plot([-3, 3], [-3, 3])\n",
    "\n",
    "err = prediction_val.flatten() - val_coords\n",
    "print('RMS error is', np.sqrt(np.mean(err**2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tflow)",
   "language": "python",
   "name": "tflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
