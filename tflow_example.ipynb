{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load processed images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_matching_ylabel(filename, ytable):\n",
    "    '''\n",
    "    Returns the corresponding AP coordinate\n",
    "    \n",
    "    Inputs:\n",
    "    - filename: the name of the image file *.tif\n",
    "    - ytable: the AP coords in the form of a pd table\n",
    "    \n",
    "    Returns: the AP coordinate, None if no match\n",
    "    '''\n",
    "    for id, label_name in enumerate(ytable.Image):\n",
    "        #print(id, label_name)\n",
    "        if filename.startswith(label_name + '_'):\n",
    "            return ytable.AP[id]\n",
    "    \n",
    "    print('Warning: no match')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_datasets(X, y):\n",
    "    '''Shuffle the datasets'''\n",
    "    order = np.random.permutation(len(y))\n",
    "    return X[order], y[order]\n",
    "    \n",
    "def load_dataset(folder, ylabel_file, num_training, num_validation, num_test):\n",
    "    '''\n",
    "    Loads a dataset\n",
    "    \n",
    "    Inputs:\n",
    "    - filename: name of the file\n",
    "    - ylabel_file: name of the ground truth label file\n",
    "    \n",
    "    Outputs:\n",
    "    Xtrain, ytrain, Xval, yval, Xtest, ytest\n",
    "    '''\n",
    "    # Now load the labels\n",
    "    y_table = pd.read_csv(ylabel_file)\n",
    "    \n",
    "    # Load the images in the folder\n",
    "    files = glob.glob(folder)\n",
    "    imlst = []\n",
    "    y_train = []\n",
    "    \n",
    "    for file in files:\n",
    "        filename = file.split('\\\\')[-1]\n",
    "        im = Image.open(file)\n",
    "        imlst.append(np.array(im))\n",
    "        \n",
    "        # Find the corresponding AP\n",
    "        APval = find_matching_ylabel(filename, y_table)\n",
    "        y_train.append(APval)\n",
    "        #print(filename, APval)\n",
    "        \n",
    "    y_train = np.array(y_train)\n",
    "    print(np.array(imlst).shape)\n",
    "    X_train = np.array(imlst)[:,:,:,np.newaxis] # Dimension N x W x H x 1 (1 channel)\n",
    "    assert len(y_train) == X_train.shape[0], \"Training and labels mismatch in length\"\n",
    "    \n",
    "    # Shuffle!\n",
    "    X_train, y_train = shuffle_datasets(X_train, y_train)\n",
    "\n",
    "    # Training and validation set\n",
    "    # Subsample the data\n",
    "    mask = range(num_training, num_training + num_validation)\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    \n",
    "    mask = range(num_training + num_validation, num_training + num_validation + num_test)\n",
    "    X_test = X_train[mask]\n",
    "    y_test = y_train[mask]\n",
    "    \n",
    "    mask = range(num_training)\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    \n",
    "\n",
    "    # Normalize the data: subtract the mean pixel and divide by std\n",
    "    mean_pixel = X_train.mean(axis=(0, 1, 2), keepdims=True)\n",
    "    std_pixel = X_train.std(axis=(0, 1, 2), keepdims=True)\n",
    "    X_train = (X_train - mean_pixel) / std_pixel\n",
    "    X_val = (X_val - mean_pixel) / std_pixel\n",
    "    X_test = (X_test - mean_pixel) / std_pixel\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_multiple(folder_lst, ylabel_lst, num_training, num_validation, num_test):\n",
    "    '''\n",
    "    Load from multiple folders\n",
    "    \n",
    "    Inputs:\n",
    "    - folder_lst: list of folders\n",
    "    - ylabel_lst: list of ylabel files\n",
    "    - num_training: list or array of number of training in each file\n",
    "    - num_validation: list of number of validation examples in each file\n",
    "    - num_test: list of number of test examples in each file\n",
    "    \n",
    "    Returns: \n",
    "    Xtrain, ytrain, Xval, yval, Xtest, ytest\n",
    "    '''\n",
    "    X_train_all, y_train_all, X_val_all, y_val_all, X_test_all, y_test_all = [], [], [], [], [], []\n",
    "    for folder, ylabel_file, ntrain, nval, ntest in zip(folder_lst, \\\n",
    "                                    ylabel_lst, num_training, num_validation, num_test):\n",
    "        X_train, y_train, X_val, y_val, X_test, y_test = load_dataset(folder, \\\n",
    "                                            ylabel_file, ntrain, nval, ntest)\n",
    "        print(y_train)\n",
    "        X_train_all.append(X_train)\n",
    "        y_train_all.append(y_train)\n",
    "        X_val_all.append(X_val)\n",
    "        y_val_all.append(y_val)\n",
    "        X_test_all.append(X_test)\n",
    "        y_test_all.append(y_test)\n",
    "        \n",
    "    # Concatenate and shuffle again\n",
    "    X_train_all = np.concatenate(X_train_all)\n",
    "    y_train_all = np.concatenate(y_train_all)\n",
    "    X_val_all = np.concatenate(X_val_all)\n",
    "    y_val_all = np.concatenate(y_val_all)\n",
    "    X_test_all = np.concatenate(X_test_all)\n",
    "    y_test_all = np.concatenate(y_test_all)\n",
    "    \n",
    "    X_train_all, y_train_all = shuffle_datasets(X_train_all, y_train_all)\n",
    "    X_val_all, y_val_all = shuffle_datasets(X_val_all, y_val_all)\n",
    "    X_test_all, y_test_all = shuffle_datasets(X_test_all, y_test_all)\n",
    "    \n",
    "    return X_train_all, y_train_all, X_val_all, y_val_all, \\\n",
    "            X_test_all, y_test_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51, 80, 100)\n",
      "[ 0.1  -0.1  -2.8  -2.7  -0.8  -0.4   2.4  -2.2  -2.9  -0.3   1.6  -2.9\n",
      "  2.    0.5  -2.6   0.25  1.7  -2.8   0.2   0.4   1.8  -3.1  -2.5   1.9\n",
      "  1.3  -2.5  -0.9  -0.5   0.6   2.2  -2.7  -2.1   2.3  -2.3   1.    0.05\n",
      " -3.   -2.4   1.4  -0.6 ]\n",
      "(38, 80, 100)\n",
      "[-3.5 -4.1 -2.8  0.4 -2.4 -3.7 -2.7 -3.1  2.1  0.8  1.1  1.7 -1.  -2.2\n",
      " -2.9 -0.5 -2.1 -2.5  1.  -1.2 -0.8 -1.6  2.3  0.   0.1  1.9 -0.2 -1.9]\n"
     ]
    }
   ],
   "source": [
    "folder_lst = ['C:\\\\Users\\\\Sur lab\\\\Documents\\\\allenCCF\\\\C07_small\\\\*.png', \\\n",
    "             'C:\\\\Users\\\\Sur lab\\\\Documents\\\\allenCCF\\\\C20_small\\\\*.tif']\n",
    "ylabel_lst = ['human_label_APcoords.csv', 'human_label_APcoords_C20.csv']\n",
    "num_training = [40, 28]\n",
    "num_validation = [6, 6]\n",
    "num_test = [5, 4]\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_dataset_multiple(folder_lst, \\\n",
    "                                    ylabel_lst, num_training, num_validation, num_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "id = 0\n",
    "plt.imshow(X_val[id,:,:,0])\n",
    "print(y_val[id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run NN model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    def __init__(self, X, y, batch_size, shuffle=False):\n",
    "        \"\"\"\n",
    "        Construct a Dataset object to iterate over data X and labels y\n",
    "        \n",
    "        Inputs:\n",
    "        - X: Numpy array of data, of any shape\n",
    "        - y: Numpy array of labels, of any shape but with y.shape[0] == X.shape[0]\n",
    "        - batch_size: Integer giving number of elements per minibatch\n",
    "        - shuffle: (optional) Boolean, whether to shuffle the data on each epoch\n",
    "        \"\"\"\n",
    "        assert X.shape[0] == y.shape[0], 'Got different numbers of data and labels'\n",
    "        self.X, self.y = X, y\n",
    "        self.batch_size, self.shuffle = batch_size, shuffle\n",
    "\n",
    "    def __iter__(self):\n",
    "        N, B = self.X.shape[0], self.batch_size\n",
    "        idxs = np.arange(N)\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(idxs)\n",
    "        return iter((self.X[i:i+B], self.y[i:i+B]) for i in range(0, N, B))\n",
    "\n",
    "\n",
    "train_dset = Dataset(X_train, y_train, batch_size=5, shuffle=True)\n",
    "val_dset = Dataset(X_val, y_val, batch_size=5, shuffle=False)\n",
    "test_dset = Dataset(X_test, y_test, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (5, 80, 100, 1) (5,)\n",
      "1 (5, 80, 100, 1) (5,)\n",
      "2 (5, 80, 100, 1) (5,)\n",
      "3 (5, 80, 100, 1) (5,)\n",
      "4 (5, 80, 100, 1) (5,)\n",
      "5 (5, 80, 100, 1) (5,)\n",
      "6 (5, 80, 100, 1) (5,)\n"
     ]
    }
   ],
   "source": [
    "# We can iterate through a dataset like this:\n",
    "for t, (x, y) in enumerate(train_dset):\n",
    "    print(t, x.shape, y.shape)\n",
    "    if t > 5: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:  /cpu:0\n"
     ]
    }
   ],
   "source": [
    "# Set up some global variables\n",
    "USE_GPU = False\n",
    "\n",
    "if USE_GPU:\n",
    "    device = '/device:GPU:0'\n",
    "else:\n",
    "    device = '/cpu:0'\n",
    "\n",
    "# Constant to control how often we print when training models\n",
    "print_every = 100\n",
    "\n",
    "print('Using device: ', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68, 80, 100, 1)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_part34(model_init_fn, optimizer_init_fn, num_epochs=1):\n",
    "    \"\"\"\n",
    "    Simple training loop for use with models defined using tf.keras. It trains\n",
    "    a model for one epoch on the CIFAR-10 training set and periodically checks\n",
    "    accuracy on the CIFAR-10 validation set.\n",
    "    \n",
    "    Inputs:\n",
    "    - model_init_fn: A function that takes no parameters; when called it\n",
    "      constructs the model we want to train: model = model_init_fn()\n",
    "    - optimizer_init_fn: A function which takes no parameters; when called it\n",
    "      constructs the Optimizer object we will use to optimize the model:\n",
    "      optimizer = optimizer_init_fn()\n",
    "    - num_epochs: The number of epochs to train for\n",
    "    \n",
    "    Returns: Nothing, but prints progress during trainingn\n",
    "    \"\"\"\n",
    "    tf.reset_default_graph()    \n",
    "    with tf.device(device):\n",
    "        # Construct the computational graph we will use to train the model. We\n",
    "        # use the model_init_fn to construct the model, declare placeholders for\n",
    "        # the data and labels\n",
    "        x = tf.placeholder(tf.float32, [None, 80, 100, 1])\n",
    "        y = tf.placeholder(tf.int32, [None])\n",
    "        \n",
    "        # We need a place holder to explicitly specify if the model is in the training\n",
    "        # phase or not. This is because a number of layers behaves differently in\n",
    "        # training and in testing, e.g., dropout and batch normalization.\n",
    "        # We pass this variable to the computation graph through feed_dict as shown below.\n",
    "        is_training = tf.placeholder(tf.bool, name='is_training')\n",
    "        \n",
    "        # Use the model function to build the forward pass.\n",
    "        scores = model_init_fn(x, is_training)\n",
    "\n",
    "        # Compute the loss like we did in Part II\n",
    "        loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=scores)\n",
    "        loss = tf.reduce_mean(loss)\n",
    "\n",
    "        # Use the optimizer_fn to construct an Optimizer, then use the optimizer\n",
    "        # to set up the training step. Asking TensorFlow to evaluate the\n",
    "        # train_op returned by optimizer.minimize(loss) will cause us to make a\n",
    "        # single update step using the current minibatch of data.\n",
    "        \n",
    "        # Note that we use tf.control_dependencies to force the model to run\n",
    "        # the tf.GraphKeys.UPDATE_OPS at each training step. tf.GraphKeys.UPDATE_OPS\n",
    "        # holds the operators that update the states of the network.\n",
    "        # For example, the tf.layers.batch_normalization function adds the running mean\n",
    "        # and variance update operators to tf.GraphKeys.UPDATE_OPS.\n",
    "        optimizer = optimizer_init_fn()\n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(update_ops):\n",
    "            train_op = optimizer.minimize(loss)\n",
    "\n",
    "    # Now we can run the computational graph many times to train the model.\n",
    "    # When we call sess.run we ask it to evaluate train_op, which causes the\n",
    "    # model to update.\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        t = 0\n",
    "        for epoch in range(num_epochs):\n",
    "            print('Starting epoch %d' % epoch)\n",
    "            for x_np, y_np in train_dset:\n",
    "                feed_dict = {x: x_np, y: y_np, is_training:1}\n",
    "                loss_np, _ = sess.run([loss, train_op], feed_dict=feed_dict)\n",
    "                if t % print_every == 0:\n",
    "                    print('Iteration %d, loss = %.4f' % (t, loss_np))\n",
    "                    check_accuracy(sess, val_dset, x, scores, is_training=is_training)\n",
    "                    print()\n",
    "                t += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerFC(tf.keras.Model):\n",
    "    def __init__(self, hidden_size, num_classes):\n",
    "        super().__init__()        \n",
    "        initializer = tf.variance_scaling_initializer(scale=2.0)\n",
    "        self.fc1 = tf.layers.Dense(hidden_size, activation=tf.nn.relu,\n",
    "                                   kernel_initializer=initializer)\n",
    "        self.fc2 = tf.layers.Dense(num_classes,\n",
    "                                   kernel_initializer=initializer)\n",
    "    def call(self, x, training=None):\n",
    "        x = tf.layers.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(sess, dset, x, scores, is_training=None):\n",
    "    \"\"\"\n",
    "    Check accuracy on a classification model.\n",
    "    \n",
    "    Inputs:\n",
    "    - sess: A TensorFlow Session that will be used to run the graph\n",
    "    - dset: A Dataset object on which to check accuracy\n",
    "    - x: A TensorFlow placeholder Tensor where input images should be fed\n",
    "    - scores: A TensorFlow Tensor representing the scores output from the\n",
    "      model; this is the Tensor we will ask TensorFlow to evaluate.\n",
    "      \n",
    "    Returns: Nothing, but prints the accuracy of the model\n",
    "    \"\"\"\n",
    "    num_correct, num_samples = 0, 0\n",
    "    for x_batch, y_batch in dset:\n",
    "        feed_dict = {x: x_batch, is_training: 0}\n",
    "        scores_np = sess.run(scores, feed_dict=feed_dict)\n",
    "        y_pred = scores_np.argmax(axis=1)\n",
    "        num_samples += x_batch.shape[0]\n",
    "        num_correct += (y_pred == y_batch).sum()\n",
    "    acc = float(num_correct) / num_samples\n",
    "    print('Got %d / %d correct (%.2f%%)' % (num_correct, num_samples, 100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 0\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Received a label value of -2 which is outside the valid range of [0, 1).  Label values: 2 -2 -2 -2 0\n\t [[node SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at <ipython-input-106-2c92aa131c5f>:35)  = SparseSoftmaxCrossEntropyWithLogits[T=DT_FLOAT, Tlabels=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](sequential/dense_1/BiasAdd, _arg_Placeholder_1_0_1)]]\n\nCaused by op 'SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits', defined at:\n  File \"C:\\Anaconda3\\envs\\tflow\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Anaconda3\\envs\\tflow\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Anaconda3\\envs\\tflow\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Anaconda3\\envs\\tflow\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Anaconda3\\envs\\tflow\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"C:\\Anaconda3\\envs\\tflow\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Anaconda3\\envs\\tflow\\lib\\asyncio\\base_events.py\", line 427, in run_forever\n    self._run_once()\n  File \"C:\\Anaconda3\\envs\\tflow\\lib\\asyncio\\base_events.py\", line 1440, in _run_once\n    handle._run()\n  File \"C:\\Anaconda3\\envs\\tflow\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Anaconda3\\envs\\tflow\\lib\\site-packages\\tornado\\ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"C:\\Anaconda3\\envs\\tflow\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Anaconda3\\envs\\tflow\\lib\\site-packages\\tornado\\gen.py\", line 1233, in inner\n    self.run()\n  File \"C:\\Anaconda3\\envs\\tflow\\lib\\site-packages\\tornado\\gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Anaconda3\\envs\\tflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Anaconda3\\envs\\tflow\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\Anaconda3\\envs\\tflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Anaconda3\\envs\\tflow\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\Anaconda3\\envs\\tflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Anaconda3\\envs\\tflow\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\Anaconda3\\envs\\tflow\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Anaconda3\\envs\\tflow\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Anaconda3\\envs\\tflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Anaconda3\\envs\\tflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"C:\\Anaconda3\\envs\\tflow\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Anaconda3\\envs\\tflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Anaconda3\\envs\\tflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3191, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"C:\\Anaconda3\\envs\\tflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-109-035173cfb63b>\", line 19, in <module>\n    train_part34(model_init_fn, optimizer_init_fn)\n  File \"<ipython-input-106-2c92aa131c5f>\", line 35, in train_part34\n    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=scores)\n  File \"C:\\Anaconda3\\envs\\tflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 2049, in sparse_softmax_cross_entropy_with_logits\n    precise_logits, labels, name=name)\n  File \"C:\\Anaconda3\\envs\\tflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 8063, in sparse_softmax_cross_entropy_with_logits\n    labels=labels, name=name)\n  File \"C:\\Anaconda3\\envs\\tflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Anaconda3\\envs\\tflow\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Anaconda3\\envs\\tflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"C:\\Anaconda3\\envs\\tflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Received a label value of -2 which is outside the valid range of [0, 1).  Label values: 2 -2 -2 -2 0\n\t [[node SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at <ipython-input-106-2c92aa131c5f>:35)  = SparseSoftmaxCrossEntropyWithLogits[T=DT_FLOAT, Tlabels=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](sequential/dense_1/BiasAdd, _arg_Placeholder_1_0_1)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Received a label value of -2 which is outside the valid range of [0, 1).  Label values: 2 -2 -2 -2 0\n\t [[{{node SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}} = SparseSoftmaxCrossEntropyWithLogits[T=DT_FLOAT, Tlabels=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](sequential/dense_1/BiasAdd, _arg_Placeholder_1_0_1)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-109-035173cfb63b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientDescentOptimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mtrain_part34\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_init_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer_init_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-106-2c92aa131c5f>\u001b[0m in \u001b[0;36mtrain_part34\u001b[1;34m(model_init_fn, optimizer_init_fn, num_epochs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mx_np\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_np\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_dset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m                 \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx_np\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my_np\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[0mloss_np\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_op\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mprint_every\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Iteration %d, loss = %.4f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_np\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1346\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1348\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1350\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Received a label value of -2 which is outside the valid range of [0, 1).  Label values: 2 -2 -2 -2 0\n\t [[node SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at <ipython-input-106-2c92aa131c5f>:35)  = SparseSoftmaxCrossEntropyWithLogits[T=DT_FLOAT, Tlabels=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](sequential/dense_1/BiasAdd, _arg_Placeholder_1_0_1)]]\n\nCaused by op 'SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits', defined at:\n  File \"C:\\Anaconda3\\envs\\tflow\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Anaconda3\\envs\\tflow\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Anaconda3\\envs\\tflow\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Anaconda3\\envs\\tflow\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Anaconda3\\envs\\tflow\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"C:\\Anaconda3\\envs\\tflow\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Anaconda3\\envs\\tflow\\lib\\asyncio\\base_events.py\", line 427, in run_forever\n    self._run_once()\n  File \"C:\\Anaconda3\\envs\\tflow\\lib\\asyncio\\base_events.py\", line 1440, in _run_once\n    handle._run()\n  File \"C:\\Anaconda3\\envs\\tflow\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Anaconda3\\envs\\tflow\\lib\\site-packages\\tornado\\ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"C:\\Anaconda3\\envs\\tflow\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Anaconda3\\envs\\tflow\\lib\\site-packages\\tornado\\gen.py\", line 1233, in inner\n    self.run()\n  File \"C:\\Anaconda3\\envs\\tflow\\lib\\site-packages\\tornado\\gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Anaconda3\\envs\\tflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Anaconda3\\envs\\tflow\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\Anaconda3\\envs\\tflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Anaconda3\\envs\\tflow\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\Anaconda3\\envs\\tflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Anaconda3\\envs\\tflow\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\Anaconda3\\envs\\tflow\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Anaconda3\\envs\\tflow\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Anaconda3\\envs\\tflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Anaconda3\\envs\\tflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"C:\\Anaconda3\\envs\\tflow\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Anaconda3\\envs\\tflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Anaconda3\\envs\\tflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3191, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"C:\\Anaconda3\\envs\\tflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-109-035173cfb63b>\", line 19, in <module>\n    train_part34(model_init_fn, optimizer_init_fn)\n  File \"<ipython-input-106-2c92aa131c5f>\", line 35, in train_part34\n    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=scores)\n  File \"C:\\Anaconda3\\envs\\tflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 2049, in sparse_softmax_cross_entropy_with_logits\n    precise_logits, labels, name=name)\n  File \"C:\\Anaconda3\\envs\\tflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 8063, in sparse_softmax_cross_entropy_with_logits\n    labels=labels, name=name)\n  File \"C:\\Anaconda3\\envs\\tflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Anaconda3\\envs\\tflow\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Anaconda3\\envs\\tflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"C:\\Anaconda3\\envs\\tflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Received a label value of -2 which is outside the valid range of [0, 1).  Label values: 2 -2 -2 -2 0\n\t [[node SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at <ipython-input-106-2c92aa131c5f>:35)  = SparseSoftmaxCrossEntropyWithLogits[T=DT_FLOAT, Tlabels=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](sequential/dense_1/BiasAdd, _arg_Placeholder_1_0_1)]]\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-2\n",
    "\n",
    "def model_init_fn(inputs, is_training):\n",
    "    input_shape = (80, 100, 1)\n",
    "    hidden_layer_size, num_classes = 2000, 1\n",
    "    initializer = tf.variance_scaling_initializer(scale=2.0)\n",
    "    layers = [\n",
    "        tf.layers.Flatten(input_shape=input_shape),\n",
    "        #tf.layers.Dense(hidden_layer_size, activation=tf.nn.relu,\n",
    "        #                kernel_initializer=initializer),\n",
    "        tf.layers.Dense(num_classes, kernel_initializer=initializer),\n",
    "    ]\n",
    "    model = tf.keras.Sequential(layers)\n",
    "    return model(inputs)\n",
    "\n",
    "def optimizer_init_fn():\n",
    "    return tf.train.GradientDescentOptimizer(learning_rate)\n",
    "\n",
    "train_part34(model_init_fn, optimizer_init_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resize and process raw images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#folder = 'C:\\\\Users\\\\Sur lab\\\\Documents\\\\allenCCF3\\\\Data\\\\MouseC07'\n",
    "folder = 'C:\\\\Users\\\\Sur lab\\\\Dropbox (MIT)\\\\Leica\\\\C07_LMN_092018_disynaptic_STRACC_mCherry_10x'\n",
    "folder2 = 'C:\\\\Users\\\\Sur lab\\Dropbox (MIT)\\\\Leica\\\\C20_LMN_CAVCreRACC_RabiesLACC_112618'\n",
    "#folder = 'C:\\\\Users\\\\Sur lab\\\\Documents\\\\allenCCF3\\\\Data\\\\MouseC07\\\\Raw'\n",
    "files = glob.glob(folder + '\\\\*\\\\*ch00.tif')\n",
    "files2 = glob.glob(folder2 + '\\\\*ch00.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = np.array([0, 2, 4, 6, 8, 10, 1, 3, 5, 7, 9, 11,\n",
    "                 12, 14, 16, 18, 20, 13, 15, 17, 19, 21,\n",
    "                 22, 24, 26, 28, 30, 32, 23, 25, 27, 29, 31, 33,\n",
    "                 34, 38, 42, 46, 50, 51, 52, 53,\n",
    "                 35, 36, 37, 39, 40, 41, 43, 44, 45, 47, 48, 49, 55, 56])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images\n",
    "bad_images = [38, 40, 44, 48, 52, 55, 59, 60, 61, 62]\n",
    "flipped_images = [26, 36, 37, 41, 42, 45, 46, 49, 50, 56, 57]\n",
    "#all_images = np.zeros((51 * 120, 80, 100, 1))\n",
    "naugment = 50\n",
    "imshape = (100, 80)\n",
    "crop_extent = 10\n",
    "\n",
    "count = 0\n",
    "imlst = []\n",
    "for i in range(len(order)):\n",
    "    #print(im.height/40, im.width/40, i)\n",
    "    if order[i] + 1 in bad_images:\n",
    "        continue\n",
    "    \n",
    "    im = Image.open(files[order[i]])\n",
    "    imresize = im.resize(imshape, Image.ANTIALIAS)\n",
    "    \n",
    "    if order[i] + 1 in flipped_images:\n",
    "        imresize = imresize.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "        \n",
    "    # Save image\n",
    "    imresize.save('C07_small/C07_im' + str(i) + '_small.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imresize = im.resize(imshape, Image.ANTIALIAS)\n",
    "    #imarr = np.array(imresize)\n",
    "    if order[i] + 1 in flipped_images:\n",
    "        imresize = imresize.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "        \n",
    "    # Save image\n",
    "    imresize.save('C07_small/C07_im' + str(i) + '.png')\n",
    "        \n",
    "    # Data augmentation\n",
    "    for i in range(naugment):\n",
    "        # Pick a random angle\n",
    "        angle = np.random.rand() * crop_extent * 2 - crop_extent\n",
    "        ver_crop = np.random.rand() * crop_extent * 2 - crop_extent\n",
    "        hor_crop = np.random.rand() * crop_extent * 2 - crop_extent\n",
    "        \n",
    "        modified1 = imresize.rotate(angle).crop((ver_crop, hor_crop, ver_crop+imshape[0], hor_crop+imshape[1]))\n",
    "        modified2 = modified1.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "        \n",
    "        modified1 = np.array(modified1)[:,:,np.newaxis] / 256\n",
    "        modified2 = np.array(modified2)[:,:,np.newaxis] / 256\n",
    "        \n",
    "        imlst += [modified1, modified2]\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "# Load C20 images\n",
    "naugment = 50\n",
    "imshape = (100, 80)\n",
    "crop_extent = 10\n",
    "\n",
    "count = 0\n",
    "imlst = []\n",
    "for i in range(len(files2)):\n",
    "    print(i)\n",
    "    \n",
    "    im = Image.open(files2[i])\n",
    "    imsave = im.resize(imshape, Image.ANTIALIAS)\n",
    "    imresize = im.resize(imshape, Image.ANTIALIAS)\n",
    "    #imarr = np.array(imresize)\n",
    "    #if order[i] + 1 in flipped_images:\n",
    "    #    imresize = imresize.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "        \n",
    "    # Save image\n",
    "    imsave.save('C20_small/C20_im' + str(i) + '_small.tif')\n",
    "    \n",
    "    imarr = np.array(imresize)[:,:,np.newaxis] / 256\n",
    "    imlst.append(imarr)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Data augmentation\n",
    "    for i in range(naugment):\n",
    "        # Pick a random angle\n",
    "        angle = np.random.rand() * crop_extent * 2 - crop_extent\n",
    "        ver_crop = np.random.rand() * crop_extent * 2 - crop_extent\n",
    "        hor_crop = np.random.rand() * crop_extent * 2 - crop_extent\n",
    "        \n",
    "        modified1 = imresize.rotate(angle).crop((ver_crop, hor_crop, ver_crop+imshape[0], hor_crop+imshape[1]))\n",
    "        modified2 = modified1.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "        \n",
    "        modified1 = np.array(modified1)[:,:,np.newaxis] / 256\n",
    "        modified2 = np.array(modified2)[:,:,np.newaxis] / 256\n",
    "        \n",
    "        imlst += [modified1, modified2]\n",
    "        #print(modified1.shape, modified2.shape)\n",
    "        \n",
    "    #all_images[count] = imarr[:,:,np.newaxis] / 256\n",
    "    \n",
    "    #count += 1\n",
    "    #plt.imshow(imarr, aspect='auto')\n",
    "    #imlst.append(imarr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zcoords = pd.read_csv('human_label_APcoords.csv')\n",
    "zcoords = zcoords[zcoords.AP < 100].AP\n",
    "zcoords = np.array(zcoords).repeat(100)\n",
    "plt.plot(zcoords)\n",
    "#plt.plot(zcoords2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = np.array(imlst)\n",
    "plt.figure(figsize=(20,15))\n",
    "for i in range(38):\n",
    "    plt.subplot(9, 7, i + 1)\n",
    "    plt.imshow(all_images[i,:,:,0], aspect='auto')\n",
    "    \n",
    "zcoords = pd.read_csv('human_label_APcoords_C20.csv')\n",
    "#zcoords = np.linspace(1.98, -2.9, 51)\n",
    "#zcoords = zcoords.repeat(naugment * 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now randomize the array\n",
    "nimages = all_images.shape[0]\n",
    "ntrain = int(nimages * 0.7)\n",
    "nval = int(nimages * 0.2)\n",
    "ntest = nimages - ntrain - nval\n",
    "\n",
    "order = np.arange(nimages)\n",
    "np.random.shuffle(order)\n",
    "\n",
    "shuffled_images = all_images[order]\n",
    "shuffled_coords = zcoords[order]\n",
    "\n",
    "train_images = shuffled_images[:ntrain]\n",
    "train_coords = shuffled_coords[:ntrain]\n",
    "val_images = shuffled_images[ntrain:(ntrain + nval)]\n",
    "val_coords = shuffled_coords[ntrain:(ntrain + nval)]\n",
    "test_images = shuffled_images[ntrain+nval:]\n",
    "test_coords = shuffled_coords[ntrain+nval:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Conv2D(32, kernel_size=(5,5), strides=(1,1),\n",
    "                            activation='relu', input_shape=(imshape[1],imshape[0],1)))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(keras.layers.Conv2D(64, (5, 5), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sgd = keras.optimizers.SGD(lr=0.1, clipnorm=1.)\n",
    "adagrad = tf.train.AdagradOptimizer(learning_rate=10)\n",
    "adam = tf.train.AdadeltaOptimizer(learning_rate=30)\n",
    "model.compile(optimizer= adam, \n",
    "              loss='mean_squared_error')\n",
    "\n",
    "model.fit(train_images, train_coords, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save trained model\n",
    "model.save('brain_slice_model_Adeltagrad.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 3\n",
    "plt.imshow(val_images[id][:,:,0])\n",
    "print('Coords = ', val_coords[id], ', predicted = ', prediction_val[id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_test = model.predict(all_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(prediction_test, zcoords.AP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zcoords.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(train_images)\n",
    "\n",
    "\n",
    "plt.scatter(train_coords, prediction)\n",
    "\n",
    "#prediction_val = model.predict(val_images)\n",
    "#plt.scatter(val_coords, prediction_val, alpha=0.5)\n",
    "\n",
    "plt.plot([-3, 3], [-3, 3])\n",
    "\n",
    "err = prediction_val.flatten() - val_coords\n",
    "print('RMS error is', np.sqrt(np.mean(err**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Keras sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar10(num_training=49000, num_validation=1000, num_test=10000):\n",
    "    \"\"\"\n",
    "    Fetch the CIFAR-10 dataset from the web and perform preprocessing to prepare\n",
    "    it for the two-layer neural net classifier. These are the same steps as\n",
    "    we used for the SVM, but condensed to a single function.\n",
    "    \"\"\"\n",
    "    # Load the raw CIFAR-10 dataset and use appropriate data types and shapes\n",
    "    cifar10 = tf.keras.datasets.cifar10.load_data()\n",
    "    (X_train, y_train), (X_test, y_test) = cifar10\n",
    "    X_train = np.asarray(X_train, dtype=np.float32)\n",
    "    y_train = np.asarray(y_train, dtype=np.int32).flatten()\n",
    "    X_test = np.asarray(X_test, dtype=np.float32)\n",
    "    y_test = np.asarray(y_test, dtype=np.int32).flatten()\n",
    "\n",
    "    # Subsample the data\n",
    "    mask = range(num_training, num_training + num_validation)\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = range(num_training)\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = range(num_test)\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "\n",
    "    # Normalize the data: subtract the mean pixel and divide by std\n",
    "    mean_pixel = X_train.mean(axis=(0, 1, 2), keepdims=True)\n",
    "    std_pixel = X_train.std(axis=(0, 1, 2), keepdims=True)\n",
    "    X_train = (X_train - mean_pixel) / std_pixel\n",
    "    X_val = (X_val - mean_pixel) / std_pixel\n",
    "    X_test = (X_test - mean_pixel) / std_pixel\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "\n",
    "# Invoke the above function to get our data.\n",
    "NHW = (0, 1, 2)\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_cifar10()\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape, y_train.dtype)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up some global variables\n",
    "USE_GPU = False\n",
    "\n",
    "if USE_GPU:\n",
    "    device = '/device:GPU:0'\n",
    "else:\n",
    "    device = '/cpu:0'\n",
    "\n",
    "# Constant to control how often we print when training models\n",
    "print_every = 100\n",
    "\n",
    "print('Using device: ', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    def __init__(self, X, y, batch_size, shuffle=False):\n",
    "        \"\"\"\n",
    "        Construct a Dataset object to iterate over data X and labels y\n",
    "        \n",
    "        Inputs:\n",
    "        - X: Numpy array of data, of any shape\n",
    "        - y: Numpy array of labels, of any shape but with y.shape[0] == X.shape[0]\n",
    "        - batch_size: Integer giving number of elements per minibatch\n",
    "        - shuffle: (optional) Boolean, whether to shuffle the data on each epoch\n",
    "        \"\"\"\n",
    "        assert X.shape[0] == y.shape[0], 'Got different numbers of data and labels'\n",
    "        self.X, self.y = X, y\n",
    "        self.batch_size, self.shuffle = batch_size, shuffle\n",
    "\n",
    "    def __iter__(self):\n",
    "        N, B = self.X.shape[0], self.batch_size\n",
    "        idxs = np.arange(N)\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(idxs)\n",
    "        return iter((self.X[i:i+B], self.y[i:i+B]) for i in range(0, N, B))\n",
    "\n",
    "\n",
    "train_dset = Dataset(X_train, y_train, batch_size=64, shuffle=True)\n",
    "val_dset = Dataset(X_val, y_val, batch_size=64, shuffle=False)\n",
    "test_dset = Dataset(X_test, y_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-2\n",
    "\n",
    "def model_init_fn(inputs, is_training):\n",
    "    input_shape = (32, 32, 3)\n",
    "    hidden_layer_size, num_classes = 4000, 10\n",
    "    initializer = tf.variance_scaling_initializer(scale=2.0)\n",
    "    layers = [\n",
    "        tf.layers.Flatten(input_shape=input_shape),\n",
    "        tf.layers.Dense(hidden_layer_size, activation=tf.nn.relu,\n",
    "                        kernel_initializer=initializer),\n",
    "        tf.layers.Dense(num_classes, kernel_initializer=initializer),\n",
    "    ]\n",
    "    model = tf.keras.Sequential(layers)\n",
    "    return model(inputs)\n",
    "\n",
    "def optimizer_init_fn():\n",
    "    return tf.train.GradientDescentOptimizer(learning_rate)\n",
    "\n",
    "train_part34(model_init_fn, optimizer_init_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tflow)",
   "language": "python",
   "name": "tflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
