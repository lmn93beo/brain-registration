{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resize and process raw images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#folder = 'C:\\\\Users\\\\Sur lab\\\\Documents\\\\allenCCF3\\\\Data\\\\MouseC07'\n",
    "folder = 'C:\\\\Users\\\\Sur lab\\\\Dropbox (MIT)\\\\Leica\\\\C07_LMN_092018_disynaptic_STRACC_mCherry_10x'\n",
    "folder2 = 'C:\\\\Users\\\\Sur lab\\Dropbox (MIT)\\\\Leica\\\\C20_LMN_CAVCreRACC_RabiesLACC_112618'\n",
    "#folder = 'C:\\\\Users\\\\Sur lab\\\\Documents\\\\allenCCF3\\\\Data\\\\MouseC07\\\\Raw'\n",
    "files = glob.glob(folder + '\\\\*\\\\*ch00.tif')\n",
    "files2 = glob.glob(folder2 + '\\\\*ch00.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = np.array([0, 2, 4, 6, 8, 10, 1, 3, 5, 7, 9, 11,\n",
    "                 12, 14, 16, 18, 20, 13, 15, 17, 19, 21,\n",
    "                 22, 24, 26, 28, 30, 32, 23, 25, 27, 29, 31, 33,\n",
    "                 34, 38, 42, 46, 50, 51, 52, 53,\n",
    "                 35, 36, 37, 39, 40, 41, 43, 44, 45, 47, 48, 49, 55, 56])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(file_lst, save_folder, order=[], bad_images=[], flipped_images=[], imshape=(100, 40)):\n",
    "    '''Load and filter out bad images\n",
    "    Saves images in a folder'''\n",
    "    if order == []:\n",
    "        order = range(len(file_lst))\n",
    "    count = 0\n",
    "    imlst = []\n",
    "    for i in range(len(order)):\n",
    "        #print(im.height/40, im.width/40, i)\n",
    "        if order[i] + 1 in bad_images:\n",
    "            continue\n",
    "        \n",
    "        # Load, resize and flip\n",
    "        im = Image.open(file_lst[order[i]])\n",
    "        imresize = im.resize(imshape, Image.ANTIALIAS)\n",
    "        if order[i] + 1 in flipped_images:\n",
    "            imresize = imresize.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "            \n",
    "        # Save image\n",
    "        imresize.save(save_folder + str(i) + '_small.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = 'C07_small_new/C07_im'\n",
    "save_folder2 = 'C20_small_new/C20_im'\n",
    "load_images(files2, save_folder2, [], [], [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load processed images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_matching_ylabel(filename, ytable):\n",
    "    '''\n",
    "    Returns the corresponding AP coordinate\n",
    "    \n",
    "    Inputs:\n",
    "    - filename: the name of the image file *.tif\n",
    "    - ytable: the AP coords in the form of a pd table\n",
    "    \n",
    "    Returns: the AP coordinate, None if no match\n",
    "    '''\n",
    "    for id, label_name in enumerate(ytable.Image):\n",
    "        #print(id, label_name)\n",
    "        if filename.startswith(label_name + '_'):\n",
    "            return ytable.AP[id]\n",
    "    \n",
    "    print('Warning: no match')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_datasets(X, y):\n",
    "    '''Shuffle the datasets'''\n",
    "    order = np.random.permutation(len(y))\n",
    "    return X[order], y[order]\n",
    "    \n",
    "def load_dataset(folder, ylabel_file, num_training, num_validation, num_test):\n",
    "    '''\n",
    "    Loads a dataset\n",
    "    \n",
    "    Inputs:\n",
    "    - filename: name of the file\n",
    "    - ylabel_file: name of the ground truth label file\n",
    "    \n",
    "    Outputs:\n",
    "    Xtrain, ytrain, Xval, yval, Xtest, ytest\n",
    "    '''\n",
    "    # Now load the labels\n",
    "    y_table = pd.read_csv(ylabel_file)\n",
    "    \n",
    "    # Load the images in the folder\n",
    "    files = glob.glob(folder)\n",
    "    imlst = []\n",
    "    y_train = []\n",
    "    \n",
    "    for file in files:\n",
    "        filename = file.split('\\\\')[-1]\n",
    "        im = Image.open(file)\n",
    "                \n",
    "        # Find the corresponding AP\n",
    "        APval = find_matching_ylabel(filename, y_table)\n",
    "        \n",
    "        imlst.append(np.array(im))\n",
    "        y_train.append(APval)\n",
    "        #print(filename, APval)\n",
    "        \n",
    "    y_train = np.array(y_train)\n",
    "    print(np.array(imlst).shape)\n",
    "    X_train = np.array(imlst)[:,:,:,np.newaxis] # Dimension N x W x H x 1 (1 channel)\n",
    "    assert len(y_train) == X_train.shape[0], \"Training and labels mismatch in length\"\n",
    "    \n",
    "    # Shuffle!\n",
    "    X_train, y_train = shuffle_datasets(X_train, y_train)\n",
    "\n",
    "    # Training and validation set\n",
    "    # Subsample the data\n",
    "    mask = range(num_training, num_training + num_validation)\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    \n",
    "    mask = range(num_training + num_validation, num_training + num_validation + num_test)\n",
    "    X_test = X_train[mask]\n",
    "    y_test = y_train[mask]\n",
    "    \n",
    "    mask = range(num_training)\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    \n",
    "\n",
    "    # Normalize the data: subtract the mean pixel and divide by std\n",
    "    #mean_pixel = X_train.mean(axis=(0, 1, 2), keepdims=True)\n",
    "    #std_pixel = X_train.std(axis=(0, 1, 2), keepdims=True)\n",
    "    #X_train = (X_train - mean_pixel) / std_pixel\n",
    "    #X_val = (X_val - mean_pixel) / std_pixel\n",
    "    #X_test = (X_test - mean_pixel) / std_pixel\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_multiple(folder_lst, ylabel_lst, num_training, num_validation, num_test):\n",
    "    '''\n",
    "    Load from multiple folders\n",
    "    \n",
    "    Inputs:\n",
    "    - folder_lst: list of folders\n",
    "    - ylabel_lst: list of ylabel files\n",
    "    - num_training: list or array of number of training in each file\n",
    "    - num_validation: list of number of validation examples in each file\n",
    "    - num_test: list of number of test examples in each file\n",
    "    \n",
    "    Returns: \n",
    "    Xtrain, ytrain, Xval, yval, Xtest, ytest\n",
    "    '''\n",
    "    X_train_all, y_train_all, X_val_all, y_val_all, X_test_all, y_test_all = [], [], [], [], [], []\n",
    "    for folder, ylabel_file, ntrain, nval, ntest in zip(folder_lst, \\\n",
    "                                    ylabel_lst, num_training, num_validation, num_test):\n",
    "        X_train, y_train, X_val, y_val, X_test, y_test = load_dataset(folder, \\\n",
    "                                            ylabel_file, ntrain, nval, ntest)\n",
    "        print(y_train)\n",
    "        X_train_all.append(X_train)\n",
    "        y_train_all.append(y_train)\n",
    "        X_val_all.append(X_val)\n",
    "        y_val_all.append(y_val)\n",
    "        X_test_all.append(X_test)\n",
    "        y_test_all.append(y_test)\n",
    "        \n",
    "    # Concatenate and shuffle again\n",
    "    X_train_all = np.concatenate(X_train_all)\n",
    "    y_train_all = np.concatenate(y_train_all)\n",
    "    X_val_all = np.concatenate(X_val_all)\n",
    "    y_val_all = np.concatenate(y_val_all)\n",
    "    X_test_all = np.concatenate(X_test_all)\n",
    "    y_test_all = np.concatenate(y_test_all)\n",
    "    \n",
    "    X_train_all, y_train_all = shuffle_datasets(X_train_all, y_train_all)\n",
    "    X_val_all, y_val_all = shuffle_datasets(X_val_all, y_val_all)\n",
    "    X_test_all, y_test_all = shuffle_datasets(X_test_all, y_test_all)\n",
    "    \n",
    "    return X_train_all, y_train_all, X_val_all, y_val_all, \\\n",
    "            X_test_all, y_test_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51, 80, 100)\n",
      "[-3.1e+00  5.0e-02  3.0e-01 -2.0e-01  1.0e-01 -2.8e+00  1.8e+00 -2.6e+00\n",
      " -4.0e-01  1.0e+00 -3.0e+00  1.7e+00  1.2e+00 -2.5e+00 -6.0e-01  5.0e-01\n",
      " -2.5e+00  1.4e+00 -2.4e+00 -9.0e-01  6.0e-01  1.9e+00 -1.0e-01  2.0e+00\n",
      "  2.0e-01 -2.6e+00  2.5e-01  2.2e+00  2.3e+00  4.0e-01  1.0e-03  1.3e+00\n",
      " -2.3e+00 -5.0e-01  1.6e+00 -8.0e-01 -3.0e-01 -2.7e+00  1.5e+00 -7.0e-01]\n",
      "(38, 80, 100)\n",
      "[-1.9  2.5  1.9  1.   0.1  2.3 -2.7 -1.2  0.8  0.  -1.3  0.4 -2.2  0.6\n",
      " -4.1 -0.7 -2.5  1.7 -2.8  1.1 -0.6 -2.4 -2.9 -3.1 -0.5 -0.3 -3.4 -3.7]\n"
     ]
    }
   ],
   "source": [
    "folder_lst = ['C:\\\\Users\\\\Sur lab\\\\Documents\\\\allenCCF\\\\C07_small\\\\*.png', \\\n",
    "             'C:\\\\Users\\\\Sur lab\\\\Documents\\\\allenCCF\\\\C20_small\\\\*.tif']\n",
    "ylabel_lst = ['human_label_APcoords.csv', 'human_label_APcoords_C20.csv']\n",
    "num_training = [40, 28]\n",
    "num_validation = [6, 6]\n",
    "num_test = [5, 4]\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_dataset_multiple(folder_lst, \\\n",
    "                                    ylabel_lst, num_training, num_validation, num_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_Xy(X_train, y_train, naugment=50, crop_extent=10):\n",
    "    '''Augment the data and shuffle\n",
    "    Inputs:\n",
    "    -X_train, y_train, the training data\n",
    "    - naugment: how many times to augment (x2 for flipping)\n",
    "    - crop_extent: how far a crop can go\n",
    "    \n",
    "    Outputs: X_aug, y_aug: the augmented data'''\n",
    "    imlst = []\n",
    "\n",
    "    # Applying only to training set?\n",
    "    for i in range(X_train.shape[0]):\n",
    "        image = X_train[i,:,:,0]\n",
    "        image = Image.fromarray(image)\n",
    "\n",
    "        for j in range(naugment):\n",
    "            # Pick a random angle\n",
    "            angle = np.random.rand() * crop_extent * 2 - crop_extent\n",
    "            ver_crop = np.random.rand() * crop_extent * 2 - crop_extent\n",
    "            hor_crop = np.random.rand() * crop_extent * 2 - crop_extent\n",
    "\n",
    "            modified1 = image.rotate(angle).crop((ver_crop, hor_crop, ver_crop+X_train.shape[2], hor_crop+X_train.shape[1]))\n",
    "            modified2 = modified1.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "\n",
    "            modified1 = np.array(modified1)[:,:,np.newaxis] / 256\n",
    "            modified2 = np.array(modified2)[:,:,np.newaxis] / 256\n",
    "\n",
    "            imlst += [modified1, modified2]\n",
    "\n",
    "    X_train_aug = np.array(imlst)\n",
    "    y_train_aug = y_train.repeat(naugment * 2)\n",
    "    return shuffle_datasets(X_train_aug, y_train_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_aug, y_train_aug = augment_Xy(X_train, y_train, 50, 10)\n",
    "X_val_aug, y_val_aug = augment_Xy(X_val, y_val, 50, 10)\n",
    "X_test_aug, y_test_aug = augment_Xy(X_test, y_test, 50, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "id = 5\n",
    "plt.imshow(X_val_aug[id,:,:,0])\n",
    "print(y_val_aug[id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run NN model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    def __init__(self, X, y, batch_size, shuffle=False):\n",
    "        \"\"\"\n",
    "        Construct a Dataset object to iterate over data X and labels y\n",
    "        \n",
    "        Inputs:\n",
    "        - X: Numpy array of data, of any shape\n",
    "        - y: Numpy array of labels, of any shape but with y.shape[0] == X.shape[0]\n",
    "        - batch_size: Integer giving number of elements per minibatch\n",
    "        - shuffle: (optional) Boolean, whether to shuffle the data on each epoch\n",
    "        \"\"\"\n",
    "        assert X.shape[0] == y.shape[0], 'Got different numbers of data and labels'\n",
    "        self.X, self.y = X, y\n",
    "        self.batch_size, self.shuffle = batch_size, shuffle\n",
    "\n",
    "    def __iter__(self):\n",
    "        N, B = self.X.shape[0], self.batch_size\n",
    "        idxs = np.arange(N)\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(idxs)\n",
    "        return iter((self.X[i:i+B], self.y[i:i+B]) for i in range(0, N, B))\n",
    "\n",
    "\n",
    "train_dset = Dataset(X_train_aug, y_train_aug, batch_size=100, shuffle=True)\n",
    "val_dset = Dataset(X_val, y_val, batch_size=5, shuffle=False)\n",
    "test_dset = Dataset(X_test, y_test, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (100, 80, 100, 1) (100,)\n",
      "1 (100, 80, 100, 1) (100,)\n",
      "2 (100, 80, 100, 1) (100,)\n",
      "3 (100, 80, 100, 1) (100,)\n",
      "4 (100, 80, 100, 1) (100,)\n",
      "5 (100, 80, 100, 1) (100,)\n",
      "6 (100, 80, 100, 1) (100,)\n"
     ]
    }
   ],
   "source": [
    "# We can iterate through a dataset like this:\n",
    "for t, (x, y) in enumerate(train_dset):\n",
    "    print(t, x.shape, y.shape)\n",
    "    if t > 5: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:  /cpu:0\n"
     ]
    }
   ],
   "source": [
    "# Set up some global variables\n",
    "USE_GPU = False\n",
    "\n",
    "if USE_GPU:\n",
    "    device = '/device:GPU:0'\n",
    "else:\n",
    "    device = '/cpu:0'\n",
    "\n",
    "# Constant to control how often we print when training models\n",
    "print_every = 100\n",
    "\n",
    "print('Using device: ', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_part34(model_init_fn, optimizer_init_fn, num_epochs=1):\n",
    "    \"\"\"\n",
    "    Simple training loop for use with models defined using tf.keras. It trains\n",
    "    a model for one epoch on the CIFAR-10 training set and periodically checks\n",
    "    accuracy on the CIFAR-10 validation set.\n",
    "    \n",
    "    Inputs:\n",
    "    - model_init_fn: A function that takes no parameters; when called it\n",
    "      constructs the model we want to train: model = model_init_fn()\n",
    "    - optimizer_init_fn: A function which takes no parameters; when called it\n",
    "      constructs the Optimizer object we will use to optimize the model:\n",
    "      optimizer = optimizer_init_fn()\n",
    "    - num_epochs: The number of epochs to train for\n",
    "    \n",
    "    Returns: Nothing, but prints progress during trainingn\n",
    "    \"\"\"\n",
    "    tf.reset_default_graph()    \n",
    "    with tf.device(device):\n",
    "        # Construct the computational graph we will use to train the model. We\n",
    "        # use the model_init_fn to construct the model, declare placeholders for\n",
    "        # the data and labels\n",
    "        x = tf.placeholder(tf.float32, [None, 80, 100, 1])\n",
    "        y = tf.placeholder(tf.int32, [None])\n",
    "        \n",
    "        # We need a place holder to explicitly specify if the model is in the training\n",
    "        # phase or not. This is because a number of layers behaves differently in\n",
    "        # training and in testing, e.g., dropout and batch normalization.\n",
    "        # We pass this variable to the computation graph through feed_dict as shown below.\n",
    "        is_training = tf.placeholder(tf.bool, name='is_training')\n",
    "        \n",
    "        # Use the model function to build the forward pass.\n",
    "        scores = model_init_fn(x, is_training)\n",
    "\n",
    "        # Compute the loss like we did in Part II\n",
    "        loss = tf.losses.mean_squared_error(labels=y, predictions=tf.reshape(scores, [-1]))\n",
    "        #loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=scores)\n",
    "        loss = tf.reduce_mean(loss)\n",
    "\n",
    "        # Use the optimizer_fn to construct an Optimizer, then use the optimizer\n",
    "        # to set up the training step. Asking TensorFlow to evaluate the\n",
    "        # train_op returned by optimizer.minimize(loss) will cause us to make a\n",
    "        # single update step using the current minibatch of data.\n",
    "        \n",
    "        # Note that we use tf.control_dependencies to force the model to run\n",
    "        # the tf.GraphKeys.UPDATE_OPS at each training step. tf.GraphKeys.UPDATE_OPS\n",
    "        # holds the operators that update the states of the network.\n",
    "        # For example, the tf.layers.batch_normalization function adds the running mean\n",
    "        # and variance update operators to tf.GraphKeys.UPDATE_OPS.\n",
    "        optimizer = optimizer_init_fn()\n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(update_ops):\n",
    "            train_op = optimizer.minimize(loss)\n",
    "\n",
    "    # Now we can run the computational graph many times to train the model.\n",
    "    # When we call sess.run we ask it to evaluate train_op, which causes the\n",
    "    # model to update.\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        t = 0\n",
    "        for epoch in range(num_epochs):\n",
    "            print('Starting epoch %d' % epoch)\n",
    "            for x_np, y_np in train_dset:\n",
    "                feed_dict = {x: x_np, y: y_np, is_training:1}\n",
    "                loss_np, _ = sess.run([loss, train_op], feed_dict=feed_dict)\n",
    "                if t % print_every == 0:\n",
    "                    print('Iteration %d, loss = %.4f' % (t, loss_np))\n",
    "                    check_accuracy(sess, val_dset, x, scores, is_training=is_training)\n",
    "                    #print()\n",
    "                t += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerFC(tf.keras.Model):\n",
    "    def __init__(self, hidden_size, num_classes):\n",
    "        super().__init__()        \n",
    "        initializer = tf.variance_scaling_initializer(scale=2.0)\n",
    "        self.fc1 = tf.layers.Dense(hidden_size, activation=tf.nn.relu,\n",
    "                                   kernel_initializer=initializer)\n",
    "        self.fc2 = tf.layers.Dense(num_classes,\n",
    "                                   kernel_initializer=initializer)\n",
    "    def call(self, x, training=None):\n",
    "        x = tf.layers.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(sess, dset, x, scores, is_training=None):\n",
    "    \"\"\"\n",
    "    Check accuracy on a classification model.\n",
    "    \n",
    "    Inputs:\n",
    "    - sess: A TensorFlow Session that will be used to run the graph\n",
    "    - dset: A Dataset object on which to check accuracy\n",
    "    - x: A TensorFlow placeholder Tensor where input images should be fed\n",
    "    - scores: A TensorFlow Tensor representing the scores output from the\n",
    "      model; this is the Tensor we will ask TensorFlow to evaluate.\n",
    "      \n",
    "    Returns: Nothing, but prints the accuracy of the model\n",
    "    \"\"\"\n",
    "    num_correct, num_samples = 0, 0\n",
    "    loss_total = 0\n",
    "    ntotal = 0\n",
    "    for x_batch, y_batch in dset:\n",
    "        feed_dict = {x: x_batch, is_training: 0}\n",
    "        scores_np = sess.run(scores, feed_dict=feed_dict)\n",
    "        loss_total += np.sum((scores_np.flatten() - y_batch.flatten()) ** 2)\n",
    "        ntotal += len(y_batch)\n",
    "        #print(ntotal)\n",
    "        \n",
    "    print('Validation loss = %.2f' % np.sqrt(loss_total / ntotal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 0\n",
      "Iteration 0, loss = 2.1011\n",
      "Validation loss = 115.57\n",
      "Starting epoch 1\n",
      "Iteration 100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 2\n",
      "Iteration 200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Iteration 300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 5\n",
      "Iteration 400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 6\n",
      "Starting epoch 7\n",
      "Iteration 500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 8\n",
      "Iteration 600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 9\n",
      "Starting epoch 10\n",
      "Iteration 700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 11\n",
      "Iteration 800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 12\n",
      "Starting epoch 13\n",
      "Iteration 900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 14\n",
      "Iteration 1000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 15\n",
      "Starting epoch 16\n",
      "Iteration 1100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 17\n",
      "Iteration 1200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 18\n",
      "Starting epoch 19\n",
      "Iteration 1300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 20\n",
      "Iteration 1400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 21\n",
      "Starting epoch 22\n",
      "Iteration 1500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 23\n",
      "Iteration 1600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 24\n",
      "Starting epoch 25\n",
      "Iteration 1700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 26\n",
      "Iteration 1800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 27\n",
      "Iteration 1900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 28\n",
      "Starting epoch 29\n",
      "Iteration 2000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 30\n",
      "Iteration 2100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 31\n",
      "Starting epoch 32\n",
      "Iteration 2200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 33\n",
      "Iteration 2300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 34\n",
      "Starting epoch 35\n",
      "Iteration 2400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 36\n",
      "Iteration 2500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 37\n",
      "Starting epoch 38\n",
      "Iteration 2600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 39\n",
      "Iteration 2700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 40\n",
      "Starting epoch 41\n",
      "Iteration 2800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 42\n",
      "Iteration 2900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 43\n",
      "Starting epoch 44\n",
      "Iteration 3000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 45\n",
      "Iteration 3100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 46\n",
      "Starting epoch 47\n",
      "Iteration 3200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 48\n",
      "Iteration 3300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 49\n",
      "Starting epoch 50\n",
      "Iteration 3400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 51\n",
      "Iteration 3500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 52\n",
      "Iteration 3600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 53\n",
      "Starting epoch 54\n",
      "Iteration 3700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 55\n",
      "Iteration 3800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 56\n",
      "Starting epoch 57\n",
      "Iteration 3900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 58\n",
      "Iteration 4000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 59\n",
      "Starting epoch 60\n",
      "Iteration 4100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 61\n",
      "Iteration 4200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 62\n",
      "Starting epoch 63\n",
      "Iteration 4300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 64\n",
      "Iteration 4400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 65\n",
      "Starting epoch 66\n",
      "Iteration 4500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 67\n",
      "Iteration 4600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 68\n",
      "Starting epoch 69\n",
      "Iteration 4700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 70\n",
      "Iteration 4800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 71\n",
      "Starting epoch 72\n",
      "Iteration 4900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 73\n",
      "Iteration 5000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 74\n",
      "Starting epoch 75\n",
      "Iteration 5100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 76\n",
      "Iteration 5200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 77\n",
      "Iteration 5300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 78\n",
      "Starting epoch 79\n",
      "Iteration 5400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 80\n",
      "Iteration 5500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 81\n",
      "Starting epoch 82\n",
      "Iteration 5600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 83\n",
      "Iteration 5700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 84\n",
      "Starting epoch 85\n",
      "Iteration 5800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 86\n",
      "Iteration 5900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 87\n",
      "Starting epoch 88\n",
      "Iteration 6000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 89\n",
      "Iteration 6100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 90\n",
      "Starting epoch 91\n",
      "Iteration 6200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 92\n",
      "Iteration 6300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 93\n",
      "Starting epoch 94\n",
      "Iteration 6400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 95\n",
      "Iteration 6500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 96\n",
      "Starting epoch 97\n",
      "Iteration 6600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 98\n",
      "Iteration 6700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 99\n",
      "Starting epoch 100\n",
      "Iteration 6800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 101\n",
      "Iteration 6900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 102\n",
      "Iteration 7000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 103\n",
      "Starting epoch 104\n",
      "Iteration 7100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 105\n",
      "Iteration 7200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 106\n",
      "Starting epoch 107\n",
      "Iteration 7300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 108\n",
      "Iteration 7400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 109\n",
      "Starting epoch 110\n",
      "Iteration 7500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 111\n",
      "Iteration 7600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 112\n",
      "Starting epoch 113\n",
      "Iteration 7700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 114\n",
      "Iteration 7800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 115\n",
      "Starting epoch 116\n",
      "Iteration 7900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 117\n",
      "Iteration 8000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 118\n",
      "Starting epoch 119\n",
      "Iteration 8100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 120\n",
      "Iteration 8200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 121\n",
      "Starting epoch 122\n",
      "Iteration 8300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 123\n",
      "Iteration 8400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 124\n",
      "Starting epoch 125\n",
      "Iteration 8500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 126\n",
      "Iteration 8600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 127\n",
      "Iteration 8700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 128\n",
      "Starting epoch 129\n",
      "Iteration 8800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 130\n",
      "Iteration 8900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 131\n",
      "Starting epoch 132\n",
      "Iteration 9000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 133\n",
      "Iteration 9100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 134\n",
      "Starting epoch 135\n",
      "Iteration 9200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 136\n",
      "Iteration 9300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 137\n",
      "Starting epoch 138\n",
      "Iteration 9400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 139\n",
      "Iteration 9500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 140\n",
      "Starting epoch 141\n",
      "Iteration 9600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 142\n",
      "Iteration 9700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 143\n",
      "Starting epoch 144\n",
      "Iteration 9800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 145\n",
      "Iteration 9900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 146\n",
      "Starting epoch 147\n",
      "Iteration 10000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 148\n",
      "Iteration 10100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 149\n",
      "Starting epoch 150\n",
      "Iteration 10200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 151\n",
      "Iteration 10300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 152\n",
      "Iteration 10400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 153\n",
      "Starting epoch 154\n",
      "Iteration 10500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 155\n",
      "Iteration 10600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 156\n",
      "Starting epoch 157\n",
      "Iteration 10700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 159\n",
      "Starting epoch 160\n",
      "Iteration 10900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 161\n",
      "Iteration 11000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 162\n",
      "Starting epoch 163\n",
      "Iteration 11100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 164\n",
      "Iteration 11200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 165\n",
      "Starting epoch 166\n",
      "Iteration 11300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 167\n",
      "Iteration 11400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 168\n",
      "Starting epoch 169\n",
      "Iteration 11500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 170\n",
      "Iteration 11600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 171\n",
      "Starting epoch 172\n",
      "Iteration 11700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 173\n",
      "Iteration 11800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 174\n",
      "Starting epoch 175\n",
      "Iteration 11900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 176\n",
      "Iteration 12000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 177\n",
      "Iteration 12100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 178\n",
      "Starting epoch 179\n",
      "Iteration 12200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 180\n",
      "Iteration 12300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 181\n",
      "Starting epoch 182\n",
      "Iteration 12400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 183\n",
      "Iteration 12500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 184\n",
      "Starting epoch 185\n",
      "Iteration 12600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 186\n",
      "Iteration 12700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 187\n",
      "Starting epoch 188\n",
      "Iteration 12800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 189\n",
      "Iteration 12900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 190\n",
      "Starting epoch 191\n",
      "Iteration 13000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 192\n",
      "Iteration 13100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 193\n",
      "Starting epoch 194\n",
      "Iteration 13200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 195\n",
      "Iteration 13300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 196\n",
      "Starting epoch 197\n",
      "Iteration 13400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 198\n",
      "Iteration 13500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 199\n",
      "Starting epoch 200\n",
      "Iteration 13600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 201\n",
      "Iteration 13700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 202\n",
      "Iteration 13800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 203\n",
      "Starting epoch 204\n",
      "Iteration 13900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 205\n",
      "Iteration 14000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 206\n",
      "Starting epoch 207\n",
      "Iteration 14100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 208\n",
      "Iteration 14200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 209\n",
      "Starting epoch 210\n",
      "Iteration 14300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 211\n",
      "Iteration 14400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 212\n",
      "Starting epoch 213\n",
      "Iteration 14500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 214\n",
      "Iteration 14600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 215\n",
      "Starting epoch 216\n",
      "Iteration 14700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 217\n",
      "Iteration 14800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 218\n",
      "Starting epoch 219\n",
      "Iteration 14900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 220\n",
      "Iteration 15000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 221\n",
      "Starting epoch 222\n",
      "Iteration 15100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 223\n",
      "Iteration 15200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 224\n",
      "Starting epoch 225\n",
      "Iteration 15300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 226\n",
      "Iteration 15400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 227\n",
      "Iteration 15500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 228\n",
      "Starting epoch 229\n",
      "Iteration 15600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 230\n",
      "Iteration 15700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 231\n",
      "Starting epoch 232\n",
      "Iteration 15800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 233\n",
      "Iteration 15900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 234\n",
      "Starting epoch 235\n",
      "Iteration 16000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 236\n",
      "Iteration 16100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 237\n",
      "Starting epoch 238\n",
      "Iteration 16200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 239\n",
      "Iteration 16300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 240\n",
      "Starting epoch 241\n",
      "Iteration 16400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 242\n",
      "Iteration 16500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 243\n",
      "Starting epoch 244\n",
      "Iteration 16600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 245\n",
      "Iteration 16700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 246\n",
      "Starting epoch 247\n",
      "Iteration 16800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 248\n",
      "Iteration 16900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 249\n",
      "Starting epoch 250\n",
      "Iteration 17000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 251\n",
      "Iteration 17100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 252\n",
      "Iteration 17200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 253\n",
      "Starting epoch 254\n",
      "Iteration 17300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 255\n",
      "Iteration 17400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 256\n",
      "Starting epoch 257\n",
      "Iteration 17500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 258\n",
      "Iteration 17600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 259\n",
      "Starting epoch 260\n",
      "Iteration 17700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 261\n",
      "Iteration 17800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 262\n",
      "Starting epoch 263\n",
      "Iteration 17900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 264\n",
      "Iteration 18000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 265\n",
      "Starting epoch 266\n",
      "Iteration 18100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 267\n",
      "Iteration 18200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 268\n",
      "Starting epoch 269\n",
      "Iteration 18300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 270\n",
      "Iteration 18400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 271\n",
      "Starting epoch 272\n",
      "Iteration 18500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 273\n",
      "Iteration 18600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 274\n",
      "Starting epoch 275\n",
      "Iteration 18700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 276\n",
      "Iteration 18800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 277\n",
      "Iteration 18900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 278\n",
      "Starting epoch 279\n",
      "Iteration 19000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 280\n",
      "Iteration 19100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 281\n",
      "Starting epoch 282\n",
      "Iteration 19200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 283\n",
      "Iteration 19300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 284\n",
      "Starting epoch 285\n",
      "Iteration 19400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 286\n",
      "Iteration 19500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 287\n",
      "Starting epoch 288\n",
      "Iteration 19600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 289\n",
      "Iteration 19700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 290\n",
      "Starting epoch 291\n",
      "Iteration 19800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 292\n",
      "Iteration 19900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 293\n",
      "Starting epoch 294\n",
      "Iteration 20000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 295\n",
      "Iteration 20100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 296\n",
      "Starting epoch 297\n",
      "Iteration 20200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 298\n",
      "Iteration 20300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 299\n",
      "Starting epoch 300\n",
      "Iteration 20400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 301\n",
      "Iteration 20500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 302\n",
      "Iteration 20600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 303\n",
      "Starting epoch 304\n",
      "Iteration 20700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 305\n",
      "Iteration 20800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 306\n",
      "Starting epoch 307\n",
      "Iteration 20900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 308\n",
      "Iteration 21000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 309\n",
      "Starting epoch 310\n",
      "Iteration 21100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 311\n",
      "Iteration 21200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 312\n",
      "Starting epoch 313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 21300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 314\n",
      "Iteration 21400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 315\n",
      "Starting epoch 316\n",
      "Iteration 21500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 317\n",
      "Iteration 21600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 318\n",
      "Starting epoch 319\n",
      "Iteration 21700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 320\n",
      "Iteration 21800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 321\n",
      "Starting epoch 322\n",
      "Iteration 21900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 323\n",
      "Iteration 22000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 324\n",
      "Starting epoch 325\n",
      "Iteration 22100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 326\n",
      "Iteration 22200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 327\n",
      "Iteration 22300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 328\n",
      "Starting epoch 329\n",
      "Iteration 22400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 330\n",
      "Iteration 22500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 331\n",
      "Starting epoch 332\n",
      "Iteration 22600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 333\n",
      "Iteration 22700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 334\n",
      "Starting epoch 335\n",
      "Iteration 22800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 336\n",
      "Iteration 22900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 337\n",
      "Starting epoch 338\n",
      "Iteration 23000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 339\n",
      "Iteration 23100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 340\n",
      "Starting epoch 341\n",
      "Iteration 23200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 342\n",
      "Iteration 23300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 343\n",
      "Starting epoch 344\n",
      "Iteration 23400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 345\n",
      "Iteration 23500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 346\n",
      "Starting epoch 347\n",
      "Iteration 23600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 348\n",
      "Iteration 23700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 349\n",
      "Starting epoch 350\n",
      "Iteration 23800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 351\n",
      "Iteration 23900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 352\n",
      "Iteration 24000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 353\n",
      "Starting epoch 354\n",
      "Iteration 24100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 355\n",
      "Iteration 24200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 356\n",
      "Starting epoch 357\n",
      "Iteration 24300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 358\n",
      "Iteration 24400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 359\n",
      "Starting epoch 360\n",
      "Iteration 24500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 361\n",
      "Iteration 24600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 362\n",
      "Starting epoch 363\n",
      "Iteration 24700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 364\n",
      "Iteration 24800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 365\n",
      "Starting epoch 366\n",
      "Iteration 24900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 367\n",
      "Iteration 25000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 368\n",
      "Starting epoch 369\n",
      "Iteration 25100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 370\n",
      "Iteration 25200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 371\n",
      "Starting epoch 372\n",
      "Iteration 25300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 373\n",
      "Iteration 25400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 374\n",
      "Starting epoch 375\n",
      "Iteration 25500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 376\n",
      "Iteration 25600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 377\n",
      "Iteration 25700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 378\n",
      "Starting epoch 379\n",
      "Iteration 25800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 380\n",
      "Iteration 25900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 381\n",
      "Starting epoch 382\n",
      "Iteration 26000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 383\n",
      "Iteration 26100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 384\n",
      "Starting epoch 385\n",
      "Iteration 26200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 386\n",
      "Iteration 26300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 387\n",
      "Starting epoch 388\n",
      "Iteration 26400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 389\n",
      "Iteration 26500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 390\n",
      "Starting epoch 391\n",
      "Iteration 26600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 392\n",
      "Iteration 26700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 393\n",
      "Starting epoch 394\n",
      "Iteration 26800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 395\n",
      "Iteration 26900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 396\n",
      "Starting epoch 397\n",
      "Iteration 27000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 398\n",
      "Iteration 27100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 399\n",
      "Starting epoch 400\n",
      "Iteration 27200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 401\n",
      "Iteration 27300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 402\n",
      "Iteration 27400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 403\n",
      "Starting epoch 404\n",
      "Iteration 27500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 405\n",
      "Iteration 27600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 406\n",
      "Starting epoch 407\n",
      "Iteration 27700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 408\n",
      "Iteration 27800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 409\n",
      "Starting epoch 410\n",
      "Iteration 27900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 411\n",
      "Iteration 28000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 412\n",
      "Starting epoch 413\n",
      "Iteration 28100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 414\n",
      "Iteration 28200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 415\n",
      "Starting epoch 416\n",
      "Iteration 28300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 417\n",
      "Iteration 28400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 418\n",
      "Starting epoch 419\n",
      "Iteration 28500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 420\n",
      "Iteration 28600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 421\n",
      "Starting epoch 422\n",
      "Iteration 28700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 423\n",
      "Iteration 28800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 424\n",
      "Starting epoch 425\n",
      "Iteration 28900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 426\n",
      "Iteration 29000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 427\n",
      "Iteration 29100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 428\n",
      "Starting epoch 429\n",
      "Iteration 29200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 430\n",
      "Iteration 29300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 431\n",
      "Starting epoch 432\n",
      "Iteration 29400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 433\n",
      "Iteration 29500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 434\n",
      "Starting epoch 435\n",
      "Iteration 29600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 436\n",
      "Iteration 29700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 437\n",
      "Starting epoch 438\n",
      "Iteration 29800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 439\n",
      "Iteration 29900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 440\n",
      "Starting epoch 441\n",
      "Iteration 30000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 442\n",
      "Iteration 30100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 443\n",
      "Starting epoch 444\n",
      "Iteration 30200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 445\n",
      "Iteration 30300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 446\n",
      "Starting epoch 447\n",
      "Iteration 30400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 448\n",
      "Iteration 30500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 449\n",
      "Starting epoch 450\n",
      "Iteration 30600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 451\n",
      "Iteration 30700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 452\n",
      "Iteration 30800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 453\n",
      "Starting epoch 454\n",
      "Iteration 30900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 455\n",
      "Iteration 31000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 456\n",
      "Starting epoch 457\n",
      "Iteration 31100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 458\n",
      "Iteration 31200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 459\n",
      "Starting epoch 460\n",
      "Iteration 31300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 461\n",
      "Iteration 31400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 462\n",
      "Starting epoch 463\n",
      "Iteration 31500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 464\n",
      "Iteration 31600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 465\n",
      "Starting epoch 466\n",
      "Iteration 31700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 467\n",
      "Iteration 31800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 468\n",
      "Starting epoch 469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 31900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 470\n",
      "Iteration 32000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 471\n",
      "Starting epoch 472\n",
      "Iteration 32100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 473\n",
      "Iteration 32200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 474\n",
      "Starting epoch 475\n",
      "Iteration 32300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 476\n",
      "Iteration 32400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 477\n",
      "Iteration 32500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 478\n",
      "Starting epoch 479\n",
      "Iteration 32600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 480\n",
      "Iteration 32700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 481\n",
      "Starting epoch 482\n",
      "Iteration 32800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 483\n",
      "Iteration 32900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 484\n",
      "Starting epoch 485\n",
      "Iteration 33000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 486\n",
      "Iteration 33100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 487\n",
      "Starting epoch 488\n",
      "Iteration 33200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 489\n",
      "Iteration 33300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 490\n",
      "Starting epoch 491\n",
      "Iteration 33400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 492\n",
      "Iteration 33500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 493\n",
      "Starting epoch 494\n",
      "Iteration 33600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 495\n",
      "Iteration 33700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 496\n",
      "Starting epoch 497\n",
      "Iteration 33800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 498\n",
      "Iteration 33900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 499\n",
      "Starting epoch 500\n",
      "Iteration 34000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 501\n",
      "Iteration 34100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 502\n",
      "Iteration 34200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 503\n",
      "Starting epoch 504\n",
      "Iteration 34300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 505\n",
      "Iteration 34400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 506\n",
      "Starting epoch 507\n",
      "Iteration 34500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 508\n",
      "Iteration 34600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 509\n",
      "Starting epoch 510\n",
      "Iteration 34700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 511\n",
      "Iteration 34800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 512\n",
      "Starting epoch 513\n",
      "Iteration 34900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 514\n",
      "Iteration 35000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 515\n",
      "Starting epoch 516\n",
      "Iteration 35100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 517\n",
      "Iteration 35200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 518\n",
      "Starting epoch 519\n",
      "Iteration 35300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 520\n",
      "Iteration 35400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 521\n",
      "Starting epoch 522\n",
      "Iteration 35500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 523\n",
      "Iteration 35600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 524\n",
      "Starting epoch 525\n",
      "Iteration 35700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 526\n",
      "Iteration 35800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 527\n",
      "Iteration 35900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 528\n",
      "Starting epoch 529\n",
      "Iteration 36000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 530\n",
      "Iteration 36100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 531\n",
      "Starting epoch 532\n",
      "Iteration 36200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 533\n",
      "Iteration 36300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 534\n",
      "Starting epoch 535\n",
      "Iteration 36400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 536\n",
      "Iteration 36500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 537\n",
      "Starting epoch 538\n",
      "Iteration 36600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 539\n",
      "Iteration 36700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 540\n",
      "Starting epoch 541\n",
      "Iteration 36800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 542\n",
      "Iteration 36900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 543\n",
      "Starting epoch 544\n",
      "Iteration 37000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 545\n",
      "Iteration 37100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 546\n",
      "Starting epoch 547\n",
      "Iteration 37200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 548\n",
      "Iteration 37300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 549\n",
      "Starting epoch 550\n",
      "Iteration 37400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 551\n",
      "Iteration 37500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 552\n",
      "Iteration 37600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 553\n",
      "Starting epoch 554\n",
      "Iteration 37700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 555\n",
      "Iteration 37800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 556\n",
      "Starting epoch 557\n",
      "Iteration 37900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 558\n",
      "Iteration 38000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 559\n",
      "Starting epoch 560\n",
      "Iteration 38100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 561\n",
      "Iteration 38200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 562\n",
      "Starting epoch 563\n",
      "Iteration 38300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 564\n",
      "Iteration 38400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 565\n",
      "Starting epoch 566\n",
      "Iteration 38500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 567\n",
      "Iteration 38600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 568\n",
      "Starting epoch 569\n",
      "Iteration 38700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 570\n",
      "Iteration 38800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 571\n",
      "Starting epoch 572\n",
      "Iteration 38900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 573\n",
      "Iteration 39000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 574\n",
      "Starting epoch 575\n",
      "Iteration 39100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 576\n",
      "Iteration 39200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 577\n",
      "Iteration 39300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 578\n",
      "Starting epoch 579\n",
      "Iteration 39400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 580\n",
      "Iteration 39500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 581\n",
      "Starting epoch 582\n",
      "Iteration 39600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 583\n",
      "Iteration 39700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 584\n",
      "Starting epoch 585\n",
      "Iteration 39800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 586\n",
      "Iteration 39900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 587\n",
      "Starting epoch 588\n",
      "Iteration 40000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 589\n",
      "Iteration 40100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 590\n",
      "Starting epoch 591\n",
      "Iteration 40200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 592\n",
      "Iteration 40300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 593\n",
      "Starting epoch 594\n",
      "Iteration 40400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 595\n",
      "Iteration 40500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 596\n",
      "Starting epoch 597\n",
      "Iteration 40600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 598\n",
      "Iteration 40700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 599\n",
      "Starting epoch 600\n",
      "Iteration 40800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 601\n",
      "Iteration 40900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 602\n",
      "Iteration 41000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 603\n",
      "Starting epoch 604\n",
      "Iteration 41100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 605\n",
      "Iteration 41200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 606\n",
      "Starting epoch 607\n",
      "Iteration 41300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 608\n",
      "Iteration 41400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 609\n",
      "Starting epoch 610\n",
      "Iteration 41500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 611\n",
      "Iteration 41600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 612\n",
      "Starting epoch 613\n",
      "Iteration 41700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 614\n",
      "Iteration 41800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 615\n",
      "Starting epoch 616\n",
      "Iteration 41900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 617\n",
      "Iteration 42000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 618\n",
      "Starting epoch 619\n",
      "Iteration 42100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 620\n",
      "Iteration 42200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 621\n",
      "Starting epoch 622\n",
      "Iteration 42300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 623\n",
      "Iteration 42400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 625\n",
      "Iteration 42500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 626\n",
      "Iteration 42600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 627\n",
      "Iteration 42700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 628\n",
      "Starting epoch 629\n",
      "Iteration 42800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 630\n",
      "Iteration 42900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 631\n",
      "Starting epoch 632\n",
      "Iteration 43000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 633\n",
      "Iteration 43100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 634\n",
      "Starting epoch 635\n",
      "Iteration 43200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 636\n",
      "Iteration 43300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 637\n",
      "Starting epoch 638\n",
      "Iteration 43400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 639\n",
      "Iteration 43500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 640\n",
      "Starting epoch 641\n",
      "Iteration 43600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 642\n",
      "Iteration 43700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 643\n",
      "Starting epoch 644\n",
      "Iteration 43800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 645\n",
      "Iteration 43900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 646\n",
      "Starting epoch 647\n",
      "Iteration 44000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 648\n",
      "Iteration 44100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 649\n",
      "Starting epoch 650\n",
      "Iteration 44200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 651\n",
      "Iteration 44300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 652\n",
      "Iteration 44400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 653\n",
      "Starting epoch 654\n",
      "Iteration 44500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 655\n",
      "Iteration 44600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 656\n",
      "Starting epoch 657\n",
      "Iteration 44700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 658\n",
      "Iteration 44800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 659\n",
      "Starting epoch 660\n",
      "Iteration 44900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 661\n",
      "Iteration 45000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 662\n",
      "Starting epoch 663\n",
      "Iteration 45100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 664\n",
      "Iteration 45200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 665\n",
      "Starting epoch 666\n",
      "Iteration 45300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 667\n",
      "Iteration 45400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 668\n",
      "Starting epoch 669\n",
      "Iteration 45500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 670\n",
      "Iteration 45600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 671\n",
      "Starting epoch 672\n",
      "Iteration 45700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 673\n",
      "Iteration 45800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 674\n",
      "Starting epoch 675\n",
      "Iteration 45900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 676\n",
      "Iteration 46000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 677\n",
      "Iteration 46100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 678\n",
      "Starting epoch 679\n",
      "Iteration 46200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 680\n",
      "Iteration 46300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 681\n",
      "Starting epoch 682\n",
      "Iteration 46400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 683\n",
      "Iteration 46500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 684\n",
      "Starting epoch 685\n",
      "Iteration 46600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 686\n",
      "Iteration 46700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 687\n",
      "Starting epoch 688\n",
      "Iteration 46800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 689\n",
      "Iteration 46900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 690\n",
      "Starting epoch 691\n",
      "Iteration 47000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 692\n",
      "Iteration 47100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 693\n",
      "Starting epoch 694\n",
      "Iteration 47200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 695\n",
      "Iteration 47300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 696\n",
      "Starting epoch 697\n",
      "Iteration 47400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 698\n",
      "Iteration 47500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 699\n",
      "Starting epoch 700\n",
      "Iteration 47600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 701\n",
      "Iteration 47700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 702\n",
      "Iteration 47800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 703\n",
      "Starting epoch 704\n",
      "Iteration 47900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 705\n",
      "Iteration 48000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 706\n",
      "Starting epoch 707\n",
      "Iteration 48100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 708\n",
      "Iteration 48200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 709\n",
      "Starting epoch 710\n",
      "Iteration 48300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 711\n",
      "Iteration 48400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 712\n",
      "Starting epoch 713\n",
      "Iteration 48500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 714\n",
      "Iteration 48600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 715\n",
      "Starting epoch 716\n",
      "Iteration 48700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 717\n",
      "Iteration 48800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 718\n",
      "Starting epoch 719\n",
      "Iteration 48900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 720\n",
      "Iteration 49000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 721\n",
      "Starting epoch 722\n",
      "Iteration 49100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 723\n",
      "Iteration 49200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 724\n",
      "Starting epoch 725\n",
      "Iteration 49300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 726\n",
      "Iteration 49400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 727\n",
      "Iteration 49500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 728\n",
      "Starting epoch 729\n",
      "Iteration 49600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 730\n",
      "Iteration 49700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 731\n",
      "Starting epoch 732\n",
      "Iteration 49800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 733\n",
      "Iteration 49900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 734\n",
      "Starting epoch 735\n",
      "Iteration 50000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 736\n",
      "Iteration 50100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 737\n",
      "Starting epoch 738\n",
      "Iteration 50200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 739\n",
      "Iteration 50300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 740\n",
      "Starting epoch 741\n",
      "Iteration 50400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 742\n",
      "Iteration 50500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 743\n",
      "Starting epoch 744\n",
      "Iteration 50600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 745\n",
      "Iteration 50700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 746\n",
      "Starting epoch 747\n",
      "Iteration 50800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 748\n",
      "Iteration 50900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 749\n",
      "Starting epoch 750\n",
      "Iteration 51000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 751\n",
      "Iteration 51100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 752\n",
      "Iteration 51200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 753\n",
      "Starting epoch 754\n",
      "Iteration 51300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 755\n",
      "Iteration 51400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 756\n",
      "Starting epoch 757\n",
      "Iteration 51500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 758\n",
      "Iteration 51600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 759\n",
      "Starting epoch 760\n",
      "Iteration 51700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 761\n",
      "Iteration 51800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 762\n",
      "Starting epoch 763\n",
      "Iteration 51900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 764\n",
      "Iteration 52000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 765\n",
      "Starting epoch 766\n",
      "Iteration 52100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 767\n",
      "Iteration 52200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 768\n",
      "Starting epoch 769\n",
      "Iteration 52300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 770\n",
      "Iteration 52400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 771\n",
      "Starting epoch 772\n",
      "Iteration 52500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 773\n",
      "Iteration 52600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 774\n",
      "Starting epoch 775\n",
      "Iteration 52700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 776\n",
      "Iteration 52800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 777\n",
      "Iteration 52900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 778\n",
      "Starting epoch 779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 53000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 780\n",
      "Iteration 53100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 781\n",
      "Starting epoch 782\n",
      "Iteration 53200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 783\n",
      "Iteration 53300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 784\n",
      "Starting epoch 785\n",
      "Iteration 53400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 786\n",
      "Iteration 53500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 787\n",
      "Starting epoch 788\n",
      "Iteration 53600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 789\n",
      "Iteration 53700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 790\n",
      "Starting epoch 791\n",
      "Iteration 53800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 792\n",
      "Iteration 53900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 793\n",
      "Starting epoch 794\n",
      "Iteration 54000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 795\n",
      "Iteration 54100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 796\n",
      "Starting epoch 797\n",
      "Iteration 54200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 798\n",
      "Iteration 54300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 799\n",
      "Starting epoch 800\n",
      "Iteration 54400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 801\n",
      "Iteration 54500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 802\n",
      "Iteration 54600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 803\n",
      "Starting epoch 804\n",
      "Iteration 54700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 805\n",
      "Iteration 54800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 806\n",
      "Starting epoch 807\n",
      "Iteration 54900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 808\n",
      "Iteration 55000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 809\n",
      "Starting epoch 810\n",
      "Iteration 55100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 811\n",
      "Iteration 55200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 812\n",
      "Starting epoch 813\n",
      "Iteration 55300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 814\n",
      "Iteration 55400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 815\n",
      "Starting epoch 816\n",
      "Iteration 55500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 817\n",
      "Iteration 55600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 818\n",
      "Starting epoch 819\n",
      "Iteration 55700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 820\n",
      "Iteration 55800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 821\n",
      "Starting epoch 822\n",
      "Iteration 55900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 823\n",
      "Iteration 56000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 824\n",
      "Starting epoch 825\n",
      "Iteration 56100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 826\n",
      "Iteration 56200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 827\n",
      "Iteration 56300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 828\n",
      "Starting epoch 829\n",
      "Iteration 56400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 830\n",
      "Iteration 56500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 831\n",
      "Starting epoch 832\n",
      "Iteration 56600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 833\n",
      "Iteration 56700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 834\n",
      "Starting epoch 835\n",
      "Iteration 56800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 836\n",
      "Iteration 56900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 837\n",
      "Starting epoch 838\n",
      "Iteration 57000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 839\n",
      "Iteration 57100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 840\n",
      "Starting epoch 841\n",
      "Iteration 57200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 842\n",
      "Iteration 57300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 843\n",
      "Starting epoch 844\n",
      "Iteration 57400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 845\n",
      "Iteration 57500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 846\n",
      "Starting epoch 847\n",
      "Iteration 57600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 848\n",
      "Iteration 57700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 849\n",
      "Starting epoch 850\n",
      "Iteration 57800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 851\n",
      "Iteration 57900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 852\n",
      "Iteration 58000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 853\n",
      "Starting epoch 854\n",
      "Iteration 58100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 855\n",
      "Iteration 58200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 856\n",
      "Starting epoch 857\n",
      "Iteration 58300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 858\n",
      "Iteration 58400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 859\n",
      "Starting epoch 860\n",
      "Iteration 58500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 861\n",
      "Iteration 58600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 862\n",
      "Starting epoch 863\n",
      "Iteration 58700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 864\n",
      "Iteration 58800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 865\n",
      "Starting epoch 866\n",
      "Iteration 58900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 867\n",
      "Iteration 59000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 868\n",
      "Starting epoch 869\n",
      "Iteration 59100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 870\n",
      "Iteration 59200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 871\n",
      "Starting epoch 872\n",
      "Iteration 59300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 873\n",
      "Iteration 59400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 874\n",
      "Starting epoch 875\n",
      "Iteration 59500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 876\n",
      "Iteration 59600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 877\n",
      "Iteration 59700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 878\n",
      "Starting epoch 879\n",
      "Iteration 59800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 880\n",
      "Iteration 59900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 881\n",
      "Starting epoch 882\n",
      "Iteration 60000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 883\n",
      "Iteration 60100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 884\n",
      "Starting epoch 885\n",
      "Iteration 60200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 886\n",
      "Iteration 60300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 887\n",
      "Starting epoch 888\n",
      "Iteration 60400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 889\n",
      "Iteration 60500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 890\n",
      "Starting epoch 891\n",
      "Iteration 60600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 892\n",
      "Iteration 60700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 893\n",
      "Starting epoch 894\n",
      "Iteration 60800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 895\n",
      "Iteration 60900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 896\n",
      "Starting epoch 897\n",
      "Iteration 61000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 898\n",
      "Iteration 61100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 899\n",
      "Starting epoch 900\n",
      "Iteration 61200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 901\n",
      "Iteration 61300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 902\n",
      "Iteration 61400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 903\n",
      "Starting epoch 904\n",
      "Iteration 61500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 905\n",
      "Iteration 61600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 906\n",
      "Starting epoch 907\n",
      "Iteration 61700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 908\n",
      "Iteration 61800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 909\n",
      "Starting epoch 910\n",
      "Iteration 61900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 911\n",
      "Iteration 62000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 912\n",
      "Starting epoch 913\n",
      "Iteration 62100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 914\n",
      "Iteration 62200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 915\n",
      "Starting epoch 916\n",
      "Iteration 62300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 917\n",
      "Iteration 62400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 918\n",
      "Starting epoch 919\n",
      "Iteration 62500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 920\n",
      "Iteration 62600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 921\n",
      "Starting epoch 922\n",
      "Iteration 62700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 923\n",
      "Iteration 62800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 924\n",
      "Starting epoch 925\n",
      "Iteration 62900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 926\n",
      "Iteration 63000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 927\n",
      "Iteration 63100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 928\n",
      "Starting epoch 929\n",
      "Iteration 63200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 930\n",
      "Iteration 63300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 931\n",
      "Starting epoch 932\n",
      "Iteration 63400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 933\n",
      "Iteration 63500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 934\n",
      "Starting epoch 935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 63600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 936\n",
      "Iteration 63700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 937\n",
      "Starting epoch 938\n",
      "Iteration 63800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 939\n",
      "Iteration 63900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 940\n",
      "Starting epoch 941\n",
      "Iteration 64000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 942\n",
      "Iteration 64100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 943\n",
      "Starting epoch 944\n",
      "Iteration 64200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 945\n",
      "Iteration 64300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 946\n",
      "Starting epoch 947\n",
      "Iteration 64400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 948\n",
      "Iteration 64500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 949\n",
      "Starting epoch 950\n",
      "Iteration 64600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 951\n",
      "Iteration 64700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 952\n",
      "Iteration 64800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 953\n",
      "Starting epoch 954\n",
      "Iteration 64900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 955\n",
      "Iteration 65000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 956\n",
      "Starting epoch 957\n",
      "Iteration 65100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 958\n",
      "Iteration 65200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 959\n",
      "Starting epoch 960\n",
      "Iteration 65300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 961\n",
      "Iteration 65400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 962\n",
      "Starting epoch 963\n",
      "Iteration 65500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 964\n",
      "Iteration 65600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 965\n",
      "Starting epoch 966\n",
      "Iteration 65700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 967\n",
      "Iteration 65800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 968\n",
      "Starting epoch 969\n",
      "Iteration 65900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 970\n",
      "Iteration 66000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 971\n",
      "Starting epoch 972\n",
      "Iteration 66100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 973\n",
      "Iteration 66200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 974\n",
      "Starting epoch 975\n",
      "Iteration 66300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 976\n",
      "Iteration 66400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 977\n",
      "Iteration 66500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 978\n",
      "Starting epoch 979\n",
      "Iteration 66600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 980\n",
      "Iteration 66700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 981\n",
      "Starting epoch 982\n",
      "Iteration 66800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 983\n",
      "Iteration 66900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 984\n",
      "Starting epoch 985\n",
      "Iteration 67000, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 986\n",
      "Iteration 67100, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 987\n",
      "Starting epoch 988\n",
      "Iteration 67200, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 989\n",
      "Iteration 67300, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 990\n",
      "Starting epoch 991\n",
      "Iteration 67400, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 992\n",
      "Iteration 67500, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 993\n",
      "Starting epoch 994\n",
      "Iteration 67600, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 995\n",
      "Iteration 67700, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 996\n",
      "Starting epoch 997\n",
      "Iteration 67800, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 998\n",
      "Iteration 67900, loss = nan\n",
      "Validation loss = nan\n",
      "Starting epoch 999\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "def model_init_fn(inputs, is_training):\n",
    "    input_shape = (80, 100, 1)\n",
    "    hidden_layer_size, num_classes = 2000, 1\n",
    "    initializer = tf.variance_scaling_initializer(scale=2.0)\n",
    "    layers = [\n",
    "        tf.layers.Flatten(input_shape=input_shape),\n",
    "        #tf.layers.Dense(hidden_layer_size, activation=tf.nn.relu,\n",
    "        #                kernel_initializer=initializer),\n",
    "        tf.layers.Dense(num_classes, kernel_initializer=initializer),\n",
    "    ]\n",
    "    model = tf.keras.Sequential(layers)\n",
    "    return model(inputs)\n",
    "\n",
    "def optimizer_init_fn():\n",
    "    return tf.train.GradientDescentOptimizer(learning_rate)\n",
    "\n",
    "train_part34(model_init_fn, optimizer_init_fn, num_epochs=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras model for NN training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshape = X_test_aug.shape[1:3]\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Conv2D(32, kernel_size=(5,5), strides=(1,1),\n",
    "                            activation='relu', input_shape=(imshape[0],imshape[1],1)))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(keras.layers.Conv2D(64, (5, 5), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data: subtract the mean pixel and divide by std\n",
    "mean_pixel = X_train_aug.mean(axis=(0, 1, 2), keepdims=True)\n",
    "std_pixel = X_train_aug.std(axis=(0, 1, 2), keepdims=True)\n",
    "X_train_aug = (X_train_aug - mean_pixel) / std_pixel\n",
    "X_val_aug = (X_val_aug - mean_pixel) / std_pixel\n",
    "X_test_aug = (X_test_aug - mean_pixel) / std_pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "6800/6800 [==============================] - 51s 8ms/step - loss: 12.5942\n",
      "Epoch 2/4\n",
      "6800/6800 [==============================] - 51s 8ms/step - loss: 3.2102\n",
      "Epoch 3/4\n",
      "6800/6800 [==============================] - 51s 7ms/step - loss: 3.1682\n",
      "Epoch 4/4\n",
      "6800/6800 [==============================] - 52s 8ms/step - loss: 3.1650\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15c14464b38>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd = keras.optimizers.SGD(lr=0.1, clipnorm=1.)\n",
    "adagrad = tf.train.AdagradOptimizer(learning_rate=10)\n",
    "adam = tf.train.AdadeltaOptimizer(learning_rate=10)\n",
    "model.compile(optimizer= adam, \n",
    "              loss='mean_squared_error')\n",
    "\n",
    "model.fit(X_train_aug, y_train_aug, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    }
   ],
   "source": [
    "# To save trained model\n",
    "model.save('brain_slice_model_Adeltagrad.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-14df7f13b20d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_images\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Coords = '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_coords\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m', predicted = '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction_val\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'val_images' is not defined"
     ]
    }
   ],
   "source": [
    "id = 3\n",
    "plt.imshow(val_images[id][:,:,0])\n",
    "print('Coords = ', val_coords[id], ', predicted = ', prediction_val[id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_test = model.predict((X_val - mean_pixel) / std_pixel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(X_val_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean((X_val/256 - mean_pixel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean((y_val - prediction_test.T)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_val, prediction_test)\n",
    "plt.plot([-3, 3], [-3, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_train_aug, prediction_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zcoords.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(train_images)\n",
    "\n",
    "\n",
    "plt.scatter(train_coords, prediction)\n",
    "\n",
    "#prediction_val = model.predict(val_images)\n",
    "#plt.scatter(val_coords, prediction_val, alpha=0.5)\n",
    "\n",
    "plt.plot([-3, 3], [-3, 3])\n",
    "\n",
    "err = prediction_val.flatten() - val_coords\n",
    "print('RMS error is', np.sqrt(np.mean(err**2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tflow)",
   "language": "python",
   "name": "tflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
